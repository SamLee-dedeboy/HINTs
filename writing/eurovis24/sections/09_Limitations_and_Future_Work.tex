\section{Limitations and Future Work}
\textbf{TODO: shorten}
The case studies demonstrate that HyperMap provides highly interpretable visualization of the topic structure and keyword connections and flexible interaction to reorganize and analyze a corpus.
During the usage, the clusters and borders help users clearly distinguish different clusters.
The topic labels assigned by LLMs coupled with keyword connections provide rich semantic information for users to make sense of the topics.
Most importantly, the user is able to focus on their domain-specific analysis tasks and does not need to understand the underlying model. 
Analysts from all disciplines are not expected to understand LLMs, hypergraphs or clustering algorithms, but they can still explore, reorganize and analyze the corpus. 
We attribute this outcome to a good model alignment. 
Hypergraphs allow us to directly map user interactions on both documents and keywords, two seemingly unrelated units of analysis, to operations on one unified model. 
LLMs assist in generating clean and interpretable preprocessed data for the modeling process.
Combined, the visualization can be designed in a way that all preprocessing and model details are irrelevant to the user during analysis.

However, there are still several limitations in the current approach.
To use LLMs for information extraction, the prompts need to be redesigned for every dataset.
Although the general template structure is the same, optimizing prompts is a time-consuming trial-and-error process.
To make it worse, the evaluation of the accuracy of a prompt relies on human judgment.
This means that the preprocessing result is not guaranteed to be error-free.
Addressing the evaluation challenge is a promising direction for future work.
We envision a combination of LLMs, computational evaluation metrics and visualizations to assist prompt evaluation. 
Another limitation is the amount of user interactions needed to converge on a satisfying corpus organization.
Although previous studies~\cite{bach2022systematic} suggest that users gain more trust and confidence while interacting with the system, 
it would be better if the system could automatically generate a satisfying organization based on user feedback.
Our current automatic cluster expansion strategy only deals with expansion, and it does not consider user intent.
We believe LLM's ability to understand user intent can be utilized to address this limitation.
Finally, the Analysis View can adopt approaches from the prompt engineering facilitation tools~\cite{petridis2023promptinfuser, dang2023choice}, or integrate more advanced document retrieval techniques~\cite{qiu2022docflow} to provide better support for analysis
Overall, with high interpretability and generalizability, it is possible to posit the users as the center of the analysis, opening up many possibilities for future work. 