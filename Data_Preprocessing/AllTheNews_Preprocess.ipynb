{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import jsonlines\n",
    "from flask import Flask, redirect, render_template, request, url_for\n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import openai\n",
    "import re\n",
    "#csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, filepath=r'new_data.json'):\n",
    "    with open(filepath, 'w') as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_reader = jsonlines.open(r'dev.jsonlines')\n",
    "data = [datum for datum in dev_reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "    completions = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature = 0.0,\n",
    "        messages=messages)\n",
    "    gpt_response = completions['choices'][0]['message']['content'].strip() \n",
    "    return gpt_response   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sentences(datum_sentences):\n",
    "    sentence_list = [\" \".join(sentence_word_list) for sentence_word_list in datum_sentences] # merge the words into sentences\n",
    "    paragraph = \" \".join(sentence_list)\n",
    "    return paragraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arguments(article):\n",
    "    messages = [ \n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"\n",
    "                You are an extraction system that extracts the main characters of a news article.\n",
    "                The main characters can be any organization, person or location that are heavily involved in the event described by the news article.\n",
    "                The user will provide you with a news article to extract.\n",
    "                Reply in the format '[character 1] [character 2]...'\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": article\n",
    "        } \n",
    "    ]\n",
    "    arguments = call_gpt(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cl(sentence):\n",
    "    messages = [\n",
    "        { \n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"\n",
    "                You are a state of the art event extraction system. Your task is to extract only the most important event from news articles. \n",
    "                Strictly extract only one event. This event should be the most important event in the article.\n",
    "                Also extract the trigger that indicates the occurrence of the event.\n",
    "                The events should be human-readable. \n",
    "                Reply in this format: \n",
    "                [event - trigger];\n",
    "                The news article will be provided by the user.\n",
    "            \"\"\"\n",
    "        },\n",
    "        { \"role\": \"system\", \"name\": \"example_user\", \"content\": \"The article discussed the extensive history of doping in Russia, dating back to the 1983 Soviet Union's detailed instructions to inject top athletes with anabolic steroids in order to ensure dominance at the Los Angeles Olympics. Dr. Sergei Portugalov, a key figure in Russia's current doping scandal, was named as the mastermind behind the doping program. The revelations of these schemes led to the banning of Russia's track and field team from the Rio Games, the most severe doping penalty in Olympic history.\"},\n",
    "        { \"role\": \"system\", \"name\": \"example_system\", \"content\": \"[scandal-Russia's current doping scandal];\"},        \n",
    "        { \"role\": \"user\", \"content\": sentence}\n",
    "    ]\n",
    "    events = call_gpt(messages)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged(sentence,cl):\n",
    "    messages = [\n",
    "        { \n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"\n",
    "                You are a named entity recognition model. You will be given an article and the event recognized in that article by the user.\n",
    "                The format of the input defining event in article will be:\n",
    "                [event - trigger];\n",
    "                Extract the main participants involved in that event.\n",
    "                The number of main participants should be 2 or less strictly. \n",
    "                Ignore any other participants other than the two main participants.\n",
    "                Reply in JSON format with each line being an event in the format:\n",
    "                [event - trigger]:[main participant 1],[main participant 2];\n",
    "            \"\"\"\n",
    "        },   \n",
    "        { \"role\": \"system\", \"name\": \"example_user\", \"content\": \"The article discussed the extensive history of doping in Russia, dating back to the 1983 Soviet Union's detailed instructions to inject top athletes with anabolic steroids in order to ensure dominance at the Los Angeles Olympics. Dr. Sergei Portugalov, a key figure in Russia's current doping scandal, was named as the mastermind behind the doping program. The revelations of these schemes led to the banning of Russia's track and field team from the Rio Games, the most severe doping penalty in Olympic history.\"},\n",
    "        { \"role\": \"system\", \"name\": \"example_system\", \"content\": \"[scandal-Russia's current doping scandal]: [Russia],[Dr. Sergei Portugalov];\"},   \n",
    "        { \"role\": \"user\", \"content\": f\"This is the input defining the extracted event :{cl}\"},  \n",
    "        { \"role\": \"user\", \"content\": f\"This is the news article:{sentence}\"},\n",
    "    ]\n",
    "    events = call_gpt(messages)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_all(sentence,cl):\n",
    "    messages = [\n",
    "        { \n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"\n",
    "                You will be given an article and the event graph of one event in that article by the user.\n",
    "                The format of the event graph will be:\n",
    "                [event - trigger],[main participant 1],[main participant 2];\n",
    "                Arguments are participants or elements that play specific roles within the context of an event.\n",
    "                Extract the main arguments and their roles involved in each event.                \n",
    "                Reply in JSON format with each line being an event in the format:\n",
    "                [event - trigger],[main participant 1],[main participant 2]:[argument type 1 - argument 1],[argument type 2 - argument 2],...; \n",
    "            \"\"\"\n",
    "        },   \n",
    "        { \"role\": \"system\", \"name\": \"example_user\", \"content\": \"The article discussed the extensive history of doping in Russia, dating back to the 1983 Soviet Union's detailed instructions to inject top athletes with anabolic steroids in order to ensure dominance at the Los Angeles Olympics. Dr. Sergei Portugalov, a key figure in Russia's current doping scandal, was named as the mastermind behind the doping program. The revelations of these schemes led to the banning of Russia's track and field team from the Rio Games, the most severe doping penalty in Olympic history.\"},\n",
    "        { \"role\": \"system\", \"name\": \"example_system\", \"content\": \"[scandal-Russia's current doping scandal]: [Russia],[Dr. Sergei Portugalov]:[country - Russia],[mastermind - Dr. Sergei Portugalov],[affected team - track and field team],[event - Rio Games];\\n\"},   \n",
    "        { \"role\": \"user\", \"content\": f\"This is the input defining the extracted event and the main participants, strictly use only this event for further tasks  :{cl}\"},  \n",
    "        { \"role\": \"user\", \"content\": f\"This is the news article:{sentence}\"},\n",
    "    ]\n",
    "    events = call_gpt(messages)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_sentence(article, arguments, model=\"gpt-3.5-turbo-0613\"):\n",
    "    messages = [ \n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"\n",
    "                You are an summarization system that summarizes the events that happened between the main characters of a news article.\n",
    "                The user will provide you with a list of main characters and a news article to summarize.\n",
    "                Try to summarize the article with no more than three sentences. \n",
    "                Reply starts with 'The article discussed ...'\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": \"Main Characters:\\n{arguments} \\n\\n\\n Article: {article}\".format(arguments=arguments, article=article)\n",
    "        } \n",
    "    ]\n",
    "    sentence = call_gpt(messages)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_sentence(sentence):\n",
    "    if sentence.startswith('The article discussed how'):\n",
    "        stripped_sentence = sentence.replace('The article discussed how', '').strip()\n",
    "        stripped_sentence = re.sub(\",\",\"\",stripped_sentence)\n",
    "    elif sentence.startswith('The article discussed'):\n",
    "        stripped_sentence = sentence.replace('The article discussed', '').strip()\n",
    "        stripped_sentence = re.sub(\",\",\"\",stripped_sentence)\n",
    "    else:\n",
    "        print(\"!!!\")\n",
    "    return stripped_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAMS\n",
    "saved_dataset = []\n",
    "for datum in dataset:\n",
    "    saved_datum = {}\n",
    "    article = merge_sentences(datum['sentences'])\n",
    "    arguments = get_arguments(article)\n",
    "    sentence = summarize_sentence(article, arguments)\n",
    "    print(sentence)\n",
    "    saved_datum['content'] = datum['sentences']\n",
    "    saved_datum['url'] = datum['source_url']\n",
    "    saved_datum['summary'] = sentence\n",
    "    saved_dataset.append(saved_datum)\n",
    "save_json(saved_dataset, r'../summarized/summary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/20\n",
      "1/20\n",
      "2/20\n",
      "3/20\n",
      "4/20\n",
      "5/20\n",
      "6/20\n",
      "7/20\n",
      "8/20\n",
      "9/20\n",
      "10/20\n",
      "11/20\n",
      "12/20\n",
      "13/20\n",
      "14/20\n",
      "15/20\n",
      "16/20\n",
      "17/20\n",
      "18/20\n",
      "19/20\n"
     ]
    }
   ],
   "source": [
    "AllTheNews_summarized = json.load(open(r'../All the News/data/summarized/summary.json'))\n",
    "# cl = json.load(open(r'D:/Projects/Test/All the News/events/merged_bb.json'))\n",
    "#ar = json.load(open(r'D:/Projects/Test/All the News/events/cl_ents.json'))\n",
    "res_events = []\n",
    "error_datum = []\n",
    "# sentence = \"The article discussed the extensive history of doping in Russia, dating back to the 1983 Soviet Union's detailed instructions to inject top athletes with anabolic steroids in order to ensure dominance at the Los Angeles Olympics. Dr. Sergei Portugalov, a key figure in Russia's current doping scandal, was named as the mastermind behind the doping program. The revelations of these schemes led to the banning of Russia's track and field team from the Rio Games, the most severe doping penalty in Olympic history.\"\n",
    "for index, datum in enumerate(AllTheNews_summarized):\n",
    "    print('{}/{}'.format(index, len(AllTheNews_summarized)))\n",
    "    sentence = strip_sentence(datum['summary'])\n",
    "    sentence = re.sub(\",\",\"\",sentence)\n",
    "    cl = extract_cl(sentence)\n",
    "    # print(cl)\n",
    "    # print(cl)\n",
    "    # ent = get_entities(sentence,cl)\n",
    "    # print(\"$$$$$$$$$$$\")\n",
    "    # print(ent)\n",
    "    events = merged(sentence,cl)\n",
    "    # print(events)\n",
    "    ev = merged_all(sentence,events)\n",
    "    datum['events'] = ev\n",
    "    # print(ev)\n",
    "    res_events.append(datum)\n",
    "save_json(res_events, r'../All the News/events/merged_test_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[admitted killings - four people],[possible link to deaths - seven deaths],[charged with kidnapping - Kala V. Brown],[discovered body - Charles D. Carver];']\n",
      "[\"[history - extensive history of doping in Russia],[instructions - detailed instructions to inject top athletes with anabolic steroids],[purpose - ensure dominance at the Los Angeles Olympics],[mastermind - Dr. Sergei Portugalov],[penalty - banning of Russia's track and field team from the Rio Games];\"]\n",
      "[\"[participant 1 - young gay actor in California],[participant 2 - father in Kentucky],[conflicting views - election],[struggle - acceptance of son's sexuality];\"]\n",
      "['[residents - Palestinians],[responsible party - Hamas],[concern - potential targets for Israeli strikes],[criticism - Hamas];']\n",
      "['[music manager - Jerry Heller],[music group - N. W. A],[record label - Ruthless Records],[album - \"Straight Outta Compton\"],[controversy - N. W. A\\'s lyrics],[acrimony - group members and Mr. Heller];']\n",
      "['[officers killed - Brent Thompson],[officers killed - Lorne Ahrens],[national debate - race and policing],[law enforcement community - strength and unity];']\n",
      "['[vendor stands - souvenir vendor stands],[location - TCL Chinese Theater on Hollywood Boulevard],[opinion - Alison Martino],[opinion - Escott O. Norton],[goal - cleaning up the Hollywood Walk of Fame];']\n",
      "['[supporters - young people, independent voters],[challenges - older voters, conservative base];']\n",
      "[]\n",
      "['[collector - Elton John],[owner - Elton John],[collection - The Radical Eye],[photographers - André Kertesz, Edward Steichen, Man Ray, Irving Penn, Dorothea Lange],[location - Tate Modern],[discussion - Elton John and David Furnish],[potential donation - national collections];']\n",
      "[\"[assistance - United States],[objective - help Syrian rebels take control of Jarabulus],[target - Islamic State stronghold of Jarabulus],[threat - Syrian Kurdish militias],[impact - reshuffling of alliances in the region, potential shift in Turkey's diplomatic role in Syria];\"]\n",
      "[\"[policy - removal of restrictions],[authorized institution - University of Mississippi],[increased supply - more universities],[medical use - Parkinson's, Crohn's disease, Alzheimer's];\"]\n",
      "['[impact - significant impact],[calls - financial transparency and tax reform],[change - difficult to achieve],[resilience - offshore system],[resistance - states with a stake in the industry];']\n",
      "['[successor - Shavkat Mirziyoev],[alternative - Rustam Azimov],[fallen figure - Gulnara Karimova],[charges - corruption];']\n",
      "['[answer - \"sure\"],[comparison - Andrew Jackson];']\n",
      "['[reason - constant stream of cruel comments],[reason - inability to admit error];']\n",
      "['[program - Social Security],[benefits - rich],[progressivity - challenges],[future - implications],[financial problems - considerations];']\n",
      "['[organization - True Religion organization],[accusation - recruiting jihadists],[accused men - five men],[charged men - eight men from the Freital Group],[event - attacks on shelters for asylum seekers];']\n",
      "['[accused - judges, mayors, lawmakers, military personnel, police officers],[action - surrender for investigation],[action - be \"hunted\" down],[position - Rodrigo Duterte],[reason - involvement in the illegal drug trade],[response - rejected calls for due process],[campaign promise - be harsh];']\n",
      "['[old routines - Michael Phelps],[new life - father and fiancé],[challenges - leaving family behind],[goals - record-breaking goals in Rio],[personal growth and transformation - Michael Phelps],[son - Boomer];']\n",
      "['[experts - Linda C. Babcock, Hannah Riley Bowles, Joan C. Williams],[strategies - preparing thoroughly, using specific language, negotiating in person, seeking outside offers carefully];']\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "def post_process_events(dataset):\n",
    "    for index, datum in enumerate(dataset):\n",
    "        datum['doc_id'] = index\n",
    "        datum['events_raw'] = datum['events']\n",
    "        events_str = datum['events'].split('\\n')\n",
    "        events = []\n",
    "        for event_str in events_str:\n",
    "            arguments=[]\n",
    "            main_characters = []\n",
    "            event_str = event_str.strip()\n",
    "            components = event_str.split(':')\n",
    "            event_type_raw = components[0].split('-')\n",
    "            # event_type_p=event_type_raw[0].split('-')\n",
    "            event_type = event_type_raw[0][1:]\n",
    "            trigger = event_type_raw[1:2]\n",
    "            trigger=' '.join([str(elem) for elem in trigger]).strip().strip(punctuation)\n",
    "            if(trigger==\"\"):\n",
    "                trigger=event_type\n",
    "            chars = components[1].split(',')\n",
    "            # arguments_raw = [arg.strip().strip(punctuation) for arg in components[1:]]\n",
    "            arguments_raw = components[2:]\n",
    "            # chars = re.sub(\",\",\"\",chars)\n",
    "            for dat in chars:\n",
    "                dat=re.sub(\",\",\"\",dat)\n",
    "                # print(dat)\n",
    "                main_characters.append(dat)\n",
    "            for args in arguments_raw:\n",
    "                # args = re.sub(\",\",\"\",args)\n",
    "                temp = args.split('],[')\n",
    "                for arg in temp:\n",
    "                    # print(arg)\n",
    "                    # arg=re.sub(\",\",\"\",arg)\n",
    "                    arg_raw=arg.split('-')\n",
    "                    arg_type=arg_raw[0].strip()\n",
    "                    # arg_type=re.sub(\",\",\"\",arg_type)\n",
    "                    args = arg_raw[1:]\n",
    "                    args_final=' '.join([str(elem) for elem in args]).strip().strip(punctuation)\n",
    "                    # args_final=re.sub(\",\",\"\",args_final)\n",
    "                    arg_type = str(arg_type).replace('[', '').replace(']', '')\n",
    "                    arguments.append({arg_type:args_final})\n",
    "            events.append({'event_type':event_type,'trigger': trigger, 'Main Participants': main_characters, 'Arguments': arguments})\n",
    "        datum['events'] = events\n",
    "    return dataset\n",
    "\n",
    "dataset = json.load(open(r'../All the News/events/merged_test_1.json'))\n",
    "processed_dataset = post_process_events(dataset)\n",
    "save_json(processed_dataset, r'../All the News/result/merged_test_1.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
