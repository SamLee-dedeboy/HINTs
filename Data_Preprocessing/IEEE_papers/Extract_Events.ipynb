{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import jsonlines\n",
    "from flask import Flask, redirect, render_template, request, url_for\n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import openai\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from numpy.linalg import norm\n",
    "import itertools\n",
    "import string\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import logging\n",
    "\n",
    "#csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, filepath=r'new_data.json'):\n",
    "    with open(filepath, 'w') as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['openai_api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv.DictReader(open(\"../IEEE_papers/Raw_data/IEEE VIS papers 1990-2022 - Main dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [datum for datum in data]\n",
    "# dataset = dataset[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(dataset, r'../IEEE_papers/processed_data/processed_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking frequency of keywords in Author keywords section of research papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = json.load(open(r'../IEEE_papers/processed_data/processed_data.json'))\n",
    "freq = {}\n",
    "for datum in dat:\n",
    "    keywords_raw = datum['AuthorKeywords'].strip()\n",
    "    keywords = keywords_raw.split(',')\n",
    "    for keys in keywords:\n",
    "        keys.strip()\n",
    "        if (keys in freq):\n",
    "            freq[keys] += 1\n",
    "        else:\n",
    "            freq[keys] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "    completions = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature = 0.0,\n",
    "        messages=messages)\n",
    "    gpt_response = completions['choices'][0]['message']['content'].strip() \n",
    "    return gpt_response   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt for extracting triggers from abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events(sentence):\n",
    "    messages = [\n",
    "        { \n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"\n",
    "                You are a state of the art event extraction system. \n",
    "                Your task is to extract only the most important event that describes the main research idea from Research paper abstract.\n",
    "                Strictly extract only one event. This event should be the major research focus of the abstract.\n",
    "                The events should be human-readable. \n",
    "                Reply in JSON format with each line being an event in the format:\n",
    "                [event];\n",
    "                The abstract of research papers will be provided by the user.\n",
    "            \"\"\"\n",
    "        },\n",
    "        { \"role\": \"system\", \"name\": \"example_user\", \"content\": \"The success of DL can be attributed to hours of parameter and architecture tuning by human experts. Neural Architecture Search (NAS) techniques aim to solve this problem by automating the search procedure for DNN architectures making it possible for non-experts to work with DNNs. Specifically, One-shot NAS techniques have recently gained popularity as they are known to reduce the search time for NAS techniques. One-Shot NAS works by training a large template network through parameter sharing which includes all the candidate NNs. This is followed by applying a procedure to rank its components through evaluating the possible candidate architectures chosen randomly. However, as these search models become increasingly powerful and diverse, they become harder to understand. Consequently, even though the search results work well, it is hard to identify search biases and control the search progression, hence a need for explainability and human-in-the-loop (HIL) One-Shot NAS. To alleviate these problems, we present NAS-Navigator, a visual analytics (VA) system aiming to solve three problems with One-Shot NAS; explainability, HIL design, and performance improvements compared to existing state-of-the-art (SOTA) techniques. NAS-Navigator gives full control of NAS back in the hands of the users while still keeping the perks of automated search, thus assisting non-expert users. Analysts can use their domain knowledge aided by cues from the interface to guide the search. Evaluation results confirm the performance of our improved One-Shot NAS algorithm is comparable to other SOTA techniques. While adding Visual Analytics (VA) using NAS-Navigator shows further improvements in search time and performance. We designed our interface in collaboration with several deep learning researchers and evaluated NAS-Navigator through a control experiment and expert interviews.\"},\n",
    "        { \"role\": \"system\", \"name\": \"example_system\", \"content\": \"[automating the search procedure for DNN architectures using Neural Architecture Search (NAS) techniques];\"},         \n",
    "        { \"role\": \"user\", \"content\": f\"This is the research paper abstract:{sentence}\"},\n",
    "    ]\n",
    "    events = call_gpt(messages)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_entities_abstract(word1, word2,abs):\n",
    "    messages = [\n",
    "        { \n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"\n",
    "                You are a state of the art classification model. \n",
    "                You will be given a pair of 2 keywords and the research paper abstract containing the keywords as user input.\n",
    "                Your task is to assign a broad and generic research topic that can represent both the words.\n",
    "                The topic should not be too specific and should be less than 3 words.\n",
    "                The topic should be very similar to the concept related to the given keywords.\n",
    "                Strictly assign one topic to a pair of keywords.\n",
    "                Remember what type was assigned to each keyword for future references.\n",
    "                Multiple keywords can belong to one topic. \n",
    "                Reply in the format:\n",
    "                research topic.\n",
    "            \"\"\"\n",
    "        },\n",
    "        # { \"role\": \"system\", \"name\": \"example_user\", \"content\": \"[Theory , Theoretical and Empirical Research]\"},\n",
    "        # { \"role\": \"system\", \"name\": \"example_system\", \"content\": \"[Theoretical Research - Theory , Theoretical and Empirical Research];\"},    \n",
    "        { \"role\": \"user\", \"content\": f\"This is the first keyword:{word1}\"},   \n",
    "        { \"role\": \"user\", \"content\": f\"This is the second keyword:{word2}\"},\n",
    "        { \"role\": \"user\", \"content\": f\"This is the abstract:{abs}\"}    \n",
    "    ]\n",
    "    events = call_gpt(messages)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_keywords(keywords):\n",
    "    messages = [\n",
    "        { \n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"\n",
    "                User will provide a list of keywords from research paper abstracts majorly talking about the same concept.\n",
    "                Remove the keywords from the list that do not belong to the same research area or concept.\n",
    "                Reply in the format:\n",
    "                \"key word 1, key word 2, ...\";\n",
    "            \"\"\"\n",
    "        },\n",
    "        { \"role\": \"system\", \"name\": \"example_user\", \"content\": \"[Data Storytelling,Deep Learning,ensemble learning,Tracking   Transformation,Motivated Perception]\"},\n",
    "        { \"role\": \"system\", \"name\": \"example_system\", \"content\": \"Deep Learning,ensemble learning\"},    \n",
    "        { \"role\": \"user\", \"content\": f\"This is the list of keywords:{keywords}\"},   \n",
    "        # { \"role\": \"user\", \"content\": f\"This is the abstract:{abs}\"}    \n",
    "    ]\n",
    "    events = call_gpt(messages)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt used for openAI embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_listEntities(keywords):\n",
    "    messages = [\n",
    "        { \n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\" \n",
    "                User will provide a list of keywords from research paper abstracts.\n",
    "                The input will be in the format:\n",
    "                key word 1, key word 2,...\n",
    "                Which phrase would best describe the list of keywords.\n",
    "                The phrase should be very specific and similar to the keywords and less than 5 words.\n",
    "                If the words are too similar to each other, simply assign one of the words as the topic.\n",
    "                Strictly assign one topic to a list of keywords.\n",
    "                Reply in the format:\n",
    "                research topic;\n",
    "            \"\"\"\n",
    "        },\n",
    "        { \"role\": \"system\", \"name\": \"example_user\", \"content\": \"[dashboards,dashboard]\"},\n",
    "        { \"role\": \"system\", \"name\": \"example_system\", \"content\": \"dashboards\"},    \n",
    "        { \"role\": \"user\", \"content\": f\"This is the list of keyword:{keywords}\"},      \n",
    "    ]\n",
    "    events = call_gpt(messages)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pairEntities(word1, word2):\n",
    "    messages = [\n",
    "        { \n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"\n",
    "                You are a state of the art classification model. \n",
    "                You will be given 2 keywords from a research paper abstract as user input.\n",
    "                Your task is to assign a generic research topic that can represent both the words.\n",
    "                The topic should not be too specific and should be less than 3 words.\n",
    "                The topic should be majorly similar to the 2 given keywords.\n",
    "                Strictly assign one topic to a pair of keywords.\n",
    "                Remember what type was assigned to each keyword for future references.\n",
    "                Multiple keywords can belong to one topic. \n",
    "                Reply in the format:\n",
    "                research topic\n",
    "            \"\"\"\n",
    "        },\n",
    "        # { \"role\": \"system\", \"name\": \"example_user\", \"content\": \"[Theory , Theoretical and Empirical Research]\"},\n",
    "        # { \"role\": \"system\", \"name\": \"example_system\", \"content\": \"[Theoretical Research - Theory , Theoretical and Empirical Research];\"},    \n",
    "        { \"role\": \"user\", \"content\": f\"This is the first keyword:{word1}\"},   \n",
    "        { \"role\": \"user\", \"content\": f\"This is the second keyword:{word2}\"},\n",
    "        # { \"role\": \"user\", \"content\": f\"This is the abstract:{abs}\"}    \n",
    "    ]\n",
    "    events = call_gpt(messages)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sentences(datum_sentences):\n",
    "    sentence_list = [\" \".join(sentence_word_list) for sentence_word_list in datum_sentences] # merge the words into sentences\n",
    "    paragraph = \" \".join(sentence_list)\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_sentence(sentence):\n",
    "    if sentence.startswith('The article discussed how'):\n",
    "        stripped_sentence = sentence.replace('The article discussed how', '').strip()\n",
    "        stripped_sentence = re.sub(\",\",\"\",stripped_sentence)\n",
    "    elif sentence.startswith('The article discussed'):\n",
    "        stripped_sentence = sentence.replace('The article discussed', '').strip()\n",
    "        stripped_sentence = re.sub(\",\",\"\",stripped_sentence)\n",
    "    else:\n",
    "        print(\"!!!\")\n",
    "    return stripped_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Triggers using gpt api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3620\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17360\\2099324457.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# keywords = datum['AuthorKeywords'].strip()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m# events = merged(sentence,cl,keywords)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# ev = merged_all(sentence,events)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17360\\155512416.py\u001b[0m in \u001b[0;36mextract_events\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;33m{\u001b[0m \u001b[1;34m\"role\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"user\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"content\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34mf\"This is the research paper abstract:{sentence}\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     ]\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mevents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_gpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17360\\2490645155.py\u001b[0m in \u001b[0;36mcall_gpt\u001b[1;34m(messages, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcall_gpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gpt-3.5-turbo-0613\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     completions = openai.ChatCompletion.create(\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    151\u001b[0m         )\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mrequest_timeout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], bool, str]:\n\u001b[1;32m--> 288\u001b[1;33m         result = self.request_raw(\n\u001b[0m\u001b[0;32m    289\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0m_thread_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession_create_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m             result = _thread_context.session.request(\n\u001b[0m\u001b[0;32m    597\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[0mabs_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    585\u001b[0m         }\n\u001b[0;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aryam\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dat = json.load(open(r'../IEEE_papers/processed_data/processed_data.json'))\n",
    "res_events = []\n",
    "error_datum = []\n",
    "for index, datum in enumerate(dat):\n",
    "    print('{}/{}'.format(index, len(dat)))\n",
    "    sentence = datum['Abstract'].strip()\n",
    "    sentence = re.sub(\"-\",\" \",sentence)\n",
    "    cl = extract_events(sentence)\n",
    "    datum['events'] = cl\n",
    "    res_events.append(datum)\n",
    "save_json(res_events, r'../IEEE_papers/Events/events_merged2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = json.load(open(r'../IEEE_papers/processed_data/processed_data.json'))\n",
    "res_events = []\n",
    "error_datum = []\n",
    "for index, datum in enumerate(keys):\n",
    "    print('{}/{}'.format(index, len(keys)))\n",
    "    sentence = datum['Abstract'].strip()\n",
    "    keywords = datum['AuthorKeywords'].strip()\n",
    "    sentence = re.sub(\"-\",\" \",sentence)\n",
    "    cl = map_entities_abstract(keys)\n",
    "    # datum['events'] = cl\n",
    "res_events.append(cl)\n",
    "save_json(res_events, r'../IEEE_papers/Events/mapped.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_punctuation_with_whitespace(input_string):\n",
    "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    return input_string.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_values(dictionary, n):\n",
    "    sorted_items = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_n_items = sorted_items[:n]\n",
    "    return dict(top_n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine(a,b):\n",
    "    cosine = np.dot(a,b)/(norm(a)*norm(b))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating openAI embeddings for keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = json.load(open(r'../IEEE_papers/Result/main_participants.json'))\n",
    "chars = chars[0:100]\n",
    "flat_list = [item.strip() for sublist in chars for item in sublist]\n",
    "flat_list = [replace_punctuation_with_whitespace(flat_list[i]) for i in range(len(flat_list))]\n",
    "flat_list = [i.lower().strip() for i in flat_list]\n",
    "flat_list = [re.sub(' +',' ',i) for i in flat_list]\n",
    "while(\"\" in flat_list):\n",
    "    flat_list.remove(\"\")\n",
    "save_json(flat_list, r'../IEEE_papers/Result/flat_list.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "photosensitivity\n",
      "$$\n",
      "photosensitive epilepsy\n",
      "$$\n",
      "accessibility\n",
      "$$\n",
      "federated learning\n",
      "$$\n",
      "data heterogeneity\n",
      "$$\n",
      "cluster analysis\n",
      "$$\n",
      "declarative specification\n",
      "$$\n",
      "self service data transformation\n",
      "$$\n",
      "programming by example\n",
      "$$\n",
      "aesthetic pleasure\n",
      "$$\n",
      "aesthetics\n",
      "$$\n",
      "validated scale\n",
      "$$\n",
      "explainability\n",
      "$$\n",
      "neural network architecture search\n",
      "$$\n",
      "deep learning\n",
      "$$\n",
      "theory\n",
      "$$\n",
      "theoretical and empirical research\n",
      "$$\n",
      "qualitative study\n",
      "$$\n",
      "confidence intervals\n",
      "$$\n",
      "bar charts\n",
      "$$\n",
      "uncertainty\n",
      "$$\n",
      "hierarchical tabular data\n",
      "$$\n",
      "tabular visualization\n",
      "$$\n",
      "tabular data\n",
      "$$\n",
      "music mood classification\n",
      "$$\n",
      "ensemble learning\n",
      "$$\n",
      "time series visualization\n",
      "$$\n",
      "kirigami\n",
      "$$\n",
      "physicalization\n",
      "$$\n",
      "aesthetics\n",
      "$$\n",
      "traces\n",
      "$$\n",
      "parallel computing\n",
      "$$\n",
      "event sequence visualization\n",
      "$$\n",
      "equity\n",
      "$$\n",
      "deficit thinking\n",
      "$$\n",
      "storytelling\n",
      "$$\n",
      "augmented merge tree\n",
      "$$\n",
      "scalar field visualization\n",
      "$$\n",
      "pixel based visualization\n",
      "$$\n",
      "gaussian mixture models\n",
      "$$\n",
      "ray casting\n",
      "$$\n",
      "scientific visualization\n",
      "$$\n",
      "beliefs\n",
      "$$\n",
      "cognition\n",
      "$$\n",
      "motivated perception\n",
      "$$\n",
      "mathematics\n",
      "$$\n",
      "physical environmental sciences\n",
      "$$\n",
      "tracking transformation\n",
      "$$\n",
      "dendrograms\n",
      "$$\n",
      "cyber physical networks\n",
      "$$\n",
      "human centered computing\n",
      "$$\n",
      "molecular dynamics\n",
      "$$\n",
      "progressive analytics\n",
      "$$\n",
      "structure\n",
      "$$\n",
      "basketball tracking data\n",
      "$$\n",
      "off ball movement analysis\n",
      "$$\n",
      "sports visualization\n",
      "$$\n",
      "parallel coordinates chart\n",
      "$$\n",
      "data storytelling\n",
      "$$\n",
      "high dimensional data visualization\n",
      "$$\n",
      "takeaways\n",
      "$$\n",
      "annotation\n",
      "$$\n",
      "line charts\n",
      "$$\n",
      "gradient descent\n",
      "$$\n",
      "graph layout\n",
      "$$\n",
      "framework\n",
      "$$\n",
      "uncertainty visualisations\n",
      "$$\n",
      "data imputation\n",
      "$$\n",
      "missing values\n",
      "$$\n",
      "icon arrays\n",
      "$$\n",
      "cross language study\n",
      "$$\n",
      "visualization\n",
      "$$\n",
      "natural language interface\n",
      "$$\n",
      "natural language understanding\n",
      "$$\n",
      "visualization authoring\n",
      "$$\n",
      "semantic inference\n",
      "$$\n",
      "table comparison\n",
      "$$\n",
      "program understanding\n",
      "$$\n",
      "cultural heritage\n",
      "$$\n",
      "fragment reassembly\n",
      "$$\n",
      "immersive visualization\n",
      "$$\n",
      "iot\n",
      "$$\n",
      "racket sports\n",
      "$$\n",
      "training\n",
      "$$\n",
      "persistence\n",
      "$$\n",
      "stability\n",
      "$$\n",
      "merge trees\n",
      "$$\n",
      "genomics\n",
      "$$\n",
      "responsive visualization\n",
      "$$\n",
      "visualization grammar\n",
      "$$\n",
      "explainable ai\n",
      "$$\n",
      "concept activation vectors\n",
      "$$\n",
      "interactive visual analytics\n",
      "$$\n",
      "sports analytics\n",
      "$$\n",
      "embedded visualization\n",
      "$$\n",
      "data visualization\n",
      "$$\n",
      "constructionism\n",
      "$$\n",
      "children\n",
      "$$\n",
      "informal learning\n",
      "$$\n",
      "toolkits\n",
      "$$\n",
      "declarative specification\n",
      "$$\n",
      "animation\n",
      "$$\n",
      "pedagogy\n",
      "$$\n",
      "game interfaces\n",
      "$$\n",
      "final project\n",
      "$$\n",
      "regional industrial structure\n",
      "$$\n",
      "spatiotemporal dynamics\n",
      "$$\n",
      "multivariate time series\n",
      "$$\n",
      "treemaps\n",
      "$$\n",
      "data centric ai\n",
      "$$\n",
      "error analysis\n",
      "$$\n",
      "embedding projection\n",
      "$$\n",
      "explicit knowledge generation\n",
      "$$\n",
      "tabular data\n",
      "$$\n",
      "augmented reality\n",
      "$$\n",
      "tangible user interface\n",
      "$$\n",
      "printed data visualization\n",
      "$$\n",
      "narrative devices\n",
      "$$\n",
      "data driven storytelling\n",
      "$$\n",
      "interaction\n",
      "$$\n",
      "nvh analysis\n",
      "$$\n",
      "structure borne noise\n",
      "$$\n",
      "interactive visual analysis\n",
      "$$\n",
      "compensation\n",
      "$$\n",
      "treemaps\n",
      "$$\n",
      "stability\n",
      "$$\n",
      "workplace safety\n",
      "$$\n",
      "ergonomic assessment\n",
      "$$\n",
      "visual analysis\n",
      "$$\n",
      "lloyd relaxation\n",
      "$$\n",
      "dot plot\n",
      "$$\n",
      "kernel frequency estimation\n",
      "$$\n",
      "dimensionality reduction\n",
      "$$\n",
      "multidimensional scaling\n",
      "$$\n",
      "non linear projection\n",
      "$$\n",
      "contour\n",
      "$$\n",
      "multiclass visualization\n",
      "$$\n",
      "domain specific language\n",
      "$$\n",
      "colorization\n",
      "$$\n",
      "emd\n",
      "$$\n",
      "color concept association\n",
      "$$\n",
      "guidance theory\n",
      "$$\n",
      "guidance implementation\n",
      "$$\n",
      "self supervised learning\n",
      "$$\n",
      "data centric ai\n",
      "$$\n",
      "semantic segmentation\n",
      "$$\n",
      "latent space\n",
      "$$\n",
      "deep learning\n",
      "$$\n",
      "scientific data representation\n",
      "$$\n",
      "openalex\n",
      "$$\n",
      "author affiliation\n",
      "$$\n",
      "scientometric analysis\n",
      "$$\n",
      "surrogate modeling\n",
      "$$\n",
      "ensemble visualization\n",
      "$$\n",
      "parameter space exploration\n",
      "$$\n",
      "zero shot models\n",
      "$$\n",
      "language modeling\n",
      "$$\n",
      "natural language processing\n",
      "$$\n",
      "trajectories\n",
      "$$\n",
      "rendering\n",
      "$$\n",
      "multivariate data\n",
      "$$\n",
      "calibration\n",
      "$$\n",
      "reliability diagram\n",
      "$$\n",
      "model understanding\n",
      "$$\n",
      "analytic provenance\n",
      "$$\n",
      "benchmark study\n",
      "$$\n",
      "machine learning\n",
      "$$\n",
      "debiasing\n",
      "$$\n",
      "causality\n",
      "$$\n",
      "algorithmic fairness\n",
      "$$\n",
      "infoshield\n",
      "$$\n",
      "human trafficking\n",
      "$$\n",
      "labeling\n",
      "$$\n",
      "webcam\n",
      "$$\n",
      "time frequency\n",
      "$$\n",
      "multi scale\n",
      "$$\n",
      "ranking\n",
      "$$\n",
      "projection\n",
      "$$\n",
      "multi attribute data exploration\n",
      "$$\n",
      "sports analytics\n",
      "$$\n",
      "multivariate event sequence\n",
      "$$\n",
      "interactive pattern mining\n",
      "$$\n",
      "delta tracking\n",
      "$$\n",
      "path tracing\n",
      "$$\n",
      "ray tracing\n",
      "$$\n",
      "color cognition\n",
      "$$\n",
      "colormap data visualizations\n",
      "$$\n",
      "visual reasoning\n",
      "$$\n",
      "overdraw\n",
      "$$\n",
      "circle packing\n",
      "$$\n",
      "overlap free\n",
      "$$\n",
      "manifold learning\n",
      "$$\n",
      "dimensionality reduction\n",
      "$$\n",
      "human centered computing\n",
      "$$\n",
      "voronoi decomposition\n",
      "$$\n",
      "statistical summarization\n",
      "$$\n",
      "isosurfaces\n",
      "$$\n",
      "dashboards\n",
      "$$\n",
      "intent\n",
      "$$\n",
      "recommendations\n",
      "$$\n",
      "interpretability\n",
      "$$\n",
      "historical cohort analysis\n",
      "$$\n",
      "machine learning\n",
      "$$\n",
      "dashboards\n",
      "$$\n",
      "storytelling\n",
      "$$\n",
      "education\n",
      "$$\n",
      "spectral decomposition\n",
      "$$\n",
      "dynamic mode decomposition\n",
      "$$\n",
      "frequency based constraints\n",
      "$$\n",
      "situated analytics\n",
      "$$\n",
      "view layout\n",
      "$$\n",
      "immersive visualization\n",
      "$$\n",
      "data centric ai\n",
      "$$\n",
      "model validation\n",
      "$$\n",
      "data slicing\n",
      "$$\n",
      "declarative grammar\n",
      "$$\n",
      "natural language interface\n",
      "$$\n",
      "interactive exploration\n",
      "$$\n",
      "hypergraphs\n",
      "$$\n",
      "maps\n",
      "$$\n",
      "storyline visualization\n",
      "$$\n",
      "e commerce\n",
      "$$\n",
      "promotion strategy\n",
      "$$\n",
      "“what if” analysis\n",
      "$$\n",
      "mixed initiative exploration\n",
      "$$\n",
      "interaction recommendation\n",
      "$$\n",
      "visualization for public education\n",
      "$$\n",
      "quantum computing\n",
      "$$\n",
      "noise awareness\n",
      "$$\n",
      "data visualization\n",
      "$$\n",
      "epidemiology\n",
      "$$\n",
      "covid 19\n",
      "$$\n",
      "epidemiological modeling\n",
      "$$\n",
      "human machine cooperation\n",
      "$$\n",
      "interpolation\n",
      "$$\n",
      "visual storytelling\n",
      "$$\n",
      "genomics\n",
      "$$\n",
      "recommendation systems\n",
      "$$\n",
      "tasks\n",
      "$$\n",
      "bipartite\n",
      "$$\n",
      "network\n",
      "$$\n",
      "evaluation\n",
      "$$\n",
      "interdisciplinary experimental science\n",
      "$$\n",
      "scientific literature data\n",
      "$$\n",
      "interactive visual analysis\n",
      "$$\n",
      "idea generation\n",
      "$$\n",
      "interview study\n",
      "$$\n",
      "examples\n",
      "$$\n",
      "foveated rendering\n",
      "$$\n",
      "neural reconstruction\n",
      "$$\n",
      "deep learning\n",
      "$$\n",
      "hypergraph\n",
      "$$\n",
      "euler diagram\n",
      "$$\n",
      "integer linear programming\n",
      "$$\n",
      "covid 19\n",
      "$$\n",
      "line charts\n",
      "$$\n",
      "multiple forecast visualizations\n",
      "$$\n",
      "human ai interaction\n",
      "$$\n",
      "transfer learning\n",
      "$$\n",
      "interactive machine learning\n",
      "$$\n",
      "radio signal\n",
      "$$\n",
      "binary sequence\n",
      "$$\n",
      "visual abstraction\n",
      "$$\n",
      "electronic health record ehr\n",
      "$$\n",
      "medicine\n",
      "$$\n",
      "close distant reading\n",
      "$$\n",
      "metaphor\n",
      "$$\n",
      "machine learning\n",
      "$$\n",
      "glyph based visualization\n",
      "$$\n",
      "fiber surfaces\n",
      "$$\n",
      "and probability\n",
      "$$\n",
      "uncertainty visualization\n",
      "$$\n",
      "smart factory\n",
      "$$\n",
      "power plant visual analytics\n",
      "$$\n",
      "spatiotemporal visualization\n",
      "$$\n",
      "progressive culling\n",
      "$$\n",
      "output sensitivity\n",
      "$$\n",
      "multivariate attribute queries\n",
      "$$\n",
      "crowdsourcing\n",
      "$$\n",
      "gaze prediction\n",
      "$$\n",
      "webcam based eye tracking\n",
      "$$\n",
      "cardinality\n",
      "$$\n",
      "intent\n",
      "$$\n",
      "comparative constructions\n",
      "$$\n",
      "data hunches\n",
      "$$\n",
      "uncertainty\n",
      "$$\n",
      "data visualization\n",
      "$$\n",
      "adapter\n",
      "$$\n",
      "word embeddings\n",
      "$$\n",
      "language model adaptation\n",
      "$$\n",
      "sensemaking\n",
      "$$\n",
      "workflow summarization\n",
      "$$\n",
      "analytic provenance\n",
      "$$\n",
      "robotic arm\n",
      "$$\n",
      "haptic feedback\n",
      "$$\n",
      "human centred interaction\n",
      "$$\n",
      "crisis\n",
      "$$\n",
      "covid 19\n",
      "$$\n",
      "dashboard\n",
      "$$\n",
      "differential privacy\n",
      "$$\n",
      "privacy preserving visualization\n",
      "$$\n",
      "tabular data\n",
      "$$\n",
      "community taxonomy\n",
      "$$\n",
      "dynamic graphs\n",
      "$$\n",
      "temporal networks\n",
      "$$\n",
      "neural architecture search\n",
      "$$\n",
      "design principle\n",
      "$$\n",
      "knowledge discovery\n",
      "$$\n",
      "augmented sports videos\n",
      "$$\n",
      "language driven authoring tool\n",
      "$$\n",
      "sports visualization\n",
      "$$\n",
      "qualitative study\n",
      "$$\n",
      "network exploration\n",
      "$$\n",
      "network visualization\n",
      "$$\n",
      "pictorial visualization\n",
      "$$\n",
      "data driven design\n",
      "$$\n",
      "learning objectives\n",
      "$$\n",
      "affective visualization\n",
      "$$\n",
      "communicative visualization\n",
      "$$\n",
      "explainable artificial intelligence\n",
      "$$\n",
      "speed prediction\n",
      "$$\n",
      "deep learning\n",
      "$$\n",
      "systematics\n",
      "$$\n",
      "routing\n",
      "$$\n",
      "focusing\n",
      "$$\n",
      "recommendation\n",
      "$$\n",
      "literature survey\n",
      "$$\n",
      "adaptive visualization\n",
      "$$\n",
      "reinforcement learning\n",
      "$$\n",
      "visualization recommendation\n",
      "$$\n",
      "multiple view visualization\n",
      "$$\n",
      "xai\n",
      "$$\n",
      "drug repurposing\n",
      "$$\n",
      "graph neural network\n",
      "$$\n",
      "urban analytics\n",
      "$$\n",
      "empirical evaluation\n",
      "$$\n",
      "urban data\n",
      "$$\n",
      "contrastive learning\n",
      "$$\n",
      "dimensionality reduction\n",
      "$$\n",
      "visual cluster analysis\n",
      "$$\n",
      "declarative specification\n",
      "$$\n",
      "survey\n",
      "$$\n",
      "domain specific languages\n",
      "$$\n",
      "discipline\n",
      "$$\n",
      "education\n",
      "$$\n",
      "cognitive abilities\n",
      "$$\n",
      "primacy effect\n",
      "$$\n",
      "attitude change\n",
      "$$\n",
      "conflicting information\n",
      "$$\n",
      "tissue imaging\n",
      "$$\n",
      "spatial analysis\n",
      "$$\n",
      "visual analytics\n",
      "$$\n",
      "digital humanities\n",
      "$$\n",
      "review\n",
      "$$\n",
      "uncertainty\n",
      "$$\n",
      "situatedness\n",
      "$$\n",
      "literature survey\n",
      "$$\n",
      "situated visualization\n",
      "$$\n",
      "caption\n",
      "$$\n",
      "disability\n",
      "$$\n",
      "blind\n",
      "$$\n",
      "chart template\n",
      "$$\n",
      "neural machine translation\n",
      "$$\n",
      "natural language interface\n",
      "$$\n",
      "tactic analysis\n",
      "$$\n",
      "stroke sequence visualization\n",
      "$$\n",
      "immersive visualization\n",
      "$$\n",
      "storytelling\n",
      "$$\n",
      "augmented sports videos\n",
      "$$\n",
      "intelligent design tool\n",
      "$$\n",
      "assistive technologies\n",
      "$$\n",
      "accessible visualization\n",
      "$$\n",
      "alternative text for graphics\n",
      "$$\n",
      "visualization recommendation\n",
      "$$\n",
      "knowledge graph\n",
      "$$\n",
      "data visualization\n",
      "$$\n",
      "dimensionality reduction\n",
      "$$\n",
      "perception based evaluation\n",
      "$$\n",
      "visual cluster analysis\n",
      "$$\n",
      "merge trees\n",
      "$$\n",
      "ensemble data\n",
      "$$\n",
      "scalar data\n",
      "$$\n",
      "user interfaces—graphical user interfaces gui\n",
      "$$\n",
      "interactive labeling\n",
      "$$\n",
      "user centered design\n",
      "$$\n",
      "explainable machine learning\n",
      "$$\n",
      "multimodal models\n",
      "$$\n",
      "sentiment analysis\n",
      "$$\n",
      "xai\n",
      "$$\n",
      "child welfare\n",
      "$$\n",
      "usability\n",
      "$$\n",
      "generative adversarial network\n",
      "$$\n",
      "spatiotemporal super resolution\n",
      "$$\n",
      "time varying data\n",
      "$$\n",
      "genomics\n",
      "$$\n",
      "declarative specification\n",
      "$$\n",
      "visualization grammar\n",
      "$$\n",
      "dashboard\n",
      "$$\n",
      "mixed initiative\n",
      "$$\n",
      "deep learning\n",
      "$$\n",
      "sensemaking\n",
      "$$\n",
      "interview study\n",
      "$$\n",
      "data workers\n",
      "$$\n",
      "visualization recommendation algorithms\n",
      "$$\n",
      "visualization tools\n",
      "$$\n",
      "urban time series\n",
      "$$\n",
      "causal graph analysis\n",
      "$$\n",
      "visual causal analysis\n",
      "$$\n",
      "nasa tlx\n",
      "$$\n",
      "online ospan\n",
      "$$\n",
      "workload\n",
      "$$\n",
      "taxonomies\n",
      "$$\n",
      "decision making\n",
      "$$\n",
      "task\n",
      "$$\n",
      "sequential pattern mining\n",
      "$$\n",
      "sports analytics\n",
      "$$\n",
      "multivariate event sequence\n",
      "$$\n",
      "healthcare\n",
      "$$\n",
      "explainable artificial intelligence\n",
      "$$\n",
      "decision making\n",
      "$$\n",
      "bias mitigation\n",
      "$$\n",
      "human bias\n",
      "$$\n",
      "decision making\n",
      "$$\n",
      "autonomous driving\n",
      "$$\n",
      "adversarial learning\n",
      "$$\n",
      "semantic segmentation\n",
      "$$\n",
      "authoring\n",
      "$$\n",
      "mixed initiative interface\n",
      "$$\n",
      "data driven storytelling\n",
      "$$\n",
      "explainable ai\n",
      "$$\n",
      "deep neural network\n",
      "$$\n",
      "model interpretation\n",
      "$$\n",
      "machine learning\n",
      "$$\n",
      "glyph based visualization\n",
      "$$\n",
      "automatic visualization\n",
      "$$\n",
      "recommendation systems\n",
      "$$\n",
      "bar charts\n",
      "$$\n",
      "perception\n",
      "$$\n",
      "datatype agnostic\n",
      "$$\n",
      "perception cognition\n",
      "$$\n",
      "diagrams\n",
      "$$\n",
      "visualization linting\n",
      "$$\n",
      "visualization optimization\n",
      "$$\n",
      "automated visualization design\n",
      "$$\n",
      "transformers\n",
      "$$\n",
      "visual question answering\n",
      "$$\n",
      "visual analytics\n",
      "$$\n",
      "freytag s pyramid\n",
      "$$\n",
      "narrative structure\n",
      "$$\n",
      "data storytelling\n",
      "$$\n",
      "e commerce warehouse\n",
      "$$\n",
      "streaming data\n",
      "$$\n",
      "order processing\n",
      "$$\n",
      "transformers\n",
      "$$\n",
      "word embeddings\n",
      "$$\n",
      "web scraper\n",
      "$$\n",
      "storytelling\n",
      "$$\n",
      "affective design\n",
      "$$\n",
      "animation\n",
      "$$\n",
      "interpretability\n",
      "$$\n",
      "contrastive learning\n",
      "$$\n",
      "dimensionality reduction\n",
      "$$\n",
      "life sciences\n",
      "$$\n",
      "mixed initiative human machine analysis\n",
      "$$\n",
      "application motivated visualization\n",
      "$$\n",
      "non linear narrative\n",
      "$$\n",
      "data comics\n",
      "$$\n",
      "interactive storytelling\n",
      "$$\n",
      "neuron embedding\n",
      "$$\n",
      "neuron clustering\n",
      "$$\n",
      "scalable summarization\n",
      "$$\n",
      "autonomous driving\n",
      "$$\n",
      "spatial video\n",
      "$$\n",
      "vision based deep learning models\n",
      "$$\n",
      "administrative justice\n",
      "$$\n",
      "explanatory visualisation\n",
      "$$\n",
      "law\n",
      "$$\n",
      "bendiness reduction\n",
      "$$\n",
      "crossing reduction\n",
      "$$\n",
      "integer linear programming\n",
      "$$\n",
      "research practice relationships\n",
      "$$\n",
      "design practice\n",
      "$$\n",
      "design process\n",
      "$$\n",
      "matrix ordering\n",
      "$$\n",
      "quality measures\n",
      "$$\n",
      "algorithms\n",
      "$$\n",
      "color cognition\n",
      "$$\n",
      "visual reasoning\n",
      "$$\n",
      "visual communication\n",
      "$$\n",
      "automatic differentiation\n",
      "$$\n",
      "differentiable rendering\n",
      "$$\n",
      "direct volume rendering\n",
      "$$\n",
      "business intelligence\n",
      "$$\n",
      "design probes\n",
      "$$\n",
      "presentation\n",
      "$$\n",
      "human ai teaming\n",
      "$$\n",
      "explainable artificial intelligence\n",
      "$$\n",
      "active learning\n",
      "$$\n",
      "covid 19\n",
      "$$\n",
      "mip\n",
      "$$\n",
      "explainable dl\n",
      "$$\n",
      "academic profiles\n",
      "$$\n",
      "career analysis\n",
      "$$\n",
      "publication data\n",
      "$$\n",
      "explainability\n",
      "$$\n",
      "affective computing\n",
      "$$\n",
      "topological data analysis\n",
      "$$\n",
      "awareness\n",
      "$$\n",
      "analytic provenance\n",
      "$$\n",
      "interaction traces\n",
      "$$\n",
      "pandemic\n",
      "$$\n",
      "ontology\n",
      "$$\n",
      "infrastructure\n",
      "$$\n",
      "pyramid\n",
      "$$\n",
      "scatterplots\n",
      "$$\n",
      "scalability\n",
      "$$\n",
      "modelling\n",
      "$$\n",
      "statistics\n",
      "$$\n",
      "machine learning\n",
      "$$\n",
      "bicluster\n",
      "$$\n",
      "cross view data relationship\n",
      "$$\n",
      "multi view visualization\n",
      "$$\n",
      "task oriented insight preservation\n",
      "$$\n",
      "responsive visualization\n",
      "$$\n",
      "video moderation\n",
      "$$\n",
      "e commerce livestreaming\n",
      "$$\n",
      "video visualization\n",
      "$$\n",
      "dynamic clustering\n",
      "$$\n",
      "social media analysis\n",
      "$$\n",
      "streaming data\n",
      "$$\n",
      "sonification\n",
      "$$\n",
      "accessibility\n",
      "$$\n",
      "sound perception\n",
      "$$\n",
      "superpowers\n",
      "$$\n",
      "empowerment\n",
      "$$\n",
      "fiction\n",
      "$$\n",
      "autonomous driving\n",
      "$$\n",
      "spatiotemporal visual analytics\n",
      "$$\n",
      "visual evaluation\n",
      "$$\n",
      "anti aliasing\n",
      "$$\n",
      "coverage\n",
      "$$\n",
      "super sampling\n",
      "$$\n",
      "disease progression\n",
      "$$\n",
      "state identification\n",
      "$$\n",
      "sequence visualization\n",
      "$$\n",
      "just noticeable difference\n",
      "$$\n",
      "charts\n",
      "$$\n",
      "modeling\n",
      "$$\n",
      "scientometry\n",
      "$$\n",
      "publication\n",
      "$$\n",
      "gender\n",
      "$$\n",
      "guidelines\n",
      "$$\n",
      "mixed initiative human machine analysis\n",
      "$$\n",
      "tabular data\n",
      "$$\n",
      "contingency tables\n",
      "$$\n",
      "causal inference\n",
      "$$\n",
      "data cognition\n",
      "$$\n",
      "mdp distortions\n",
      "$$\n",
      "inter cluster reliability\n",
      "$$\n",
      "distortion metrics\n",
      "$$\n",
      "histopathology\n",
      "$$\n",
      "focus context\n",
      "$$\n",
      "image analysis\n",
      "$$\n",
      "glyphs\n",
      "$$\n",
      "small multiples\n",
      "$$\n",
      "generative design\n",
      "$$\n",
      "perception cognition\n",
      "$$\n",
      "human subjects quantitative studies\n",
      "$$\n",
      "personal informatics\n",
      "$$\n",
      "interview methods\n",
      "$$\n",
      "personal visual analytics\n",
      "$$\n",
      "fairness\n",
      "$$\n",
      "graph ranking\n",
      "$$\n",
      "visual analytics\n",
      "$$\n",
      "infographics\n",
      "$$\n",
      "reusable templates\n",
      "$$\n",
      "graphic design\n",
      "$$\n",
      "retirement investing\n",
      "$$\n",
      "equity premium puzzle\n",
      "$$\n",
      "myopic loss aversion\n",
      "$$\n",
      "many time series\n",
      "$$\n",
      "density based visualization\n",
      "$$\n",
      "interactive visualization for large scale data\n",
      "$$\n",
      "bitcoin\n",
      "$$\n",
      "pool hopping\n",
      "$$\n",
      "mining pools\n",
      "$$\n",
      "exemplars\n",
      "$$\n",
      "cancer cell lines\n",
      "$$\n",
      "microscopy visualization\n",
      "$$\n",
      "t stochastic neighbor embedding\n",
      "$$\n",
      "embedding\n",
      "$$\n",
      "projection\n",
      "$$\n"
     ]
    }
   ],
   "source": [
    "openAI_embedds = {}\n",
    "for i in flat_list:\n",
    "    embed = get_embedding(i)\n",
    "    openAI_embedds[i] = embed\n",
    "\n",
    "save_json(openAI_embedds, r'../IEEE_papers/Result/openAI_embeddings_2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate similar words mapping fop openAI embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['declarative specification', 'declarative grammar'], '^^^^^^^^^^^']\n",
      "[[0.9453816242137059], '@@@']\n",
      "0.9453816242137059\n",
      "['declarative specification', 'declarative grammar']\n",
      "$$$\n",
      "[['hierarchical tabular data', 'tabular data'], '^^^^^^^^^^^']\n",
      "[[0.94971870809219], '@@@']\n",
      "0.94971870809219\n",
      "['hierarchical tabular data', 'tabular data']\n",
      "$$$\n",
      "[['time series visualization', 'multivariate time series'], '^^^^^^^^^^^']\n",
      "[[0.9570334227312306], '@@@']\n",
      "0.9570334227312306\n",
      "['time series visualization', 'multivariate time series']\n",
      "$$$\n",
      "[['storytelling', 'visual storytelling'], '^^^^^^^^^^^']\n",
      "[[0.944345009798009], '@@@']\n",
      "0.944345009798009\n",
      "['storytelling', 'visual storytelling']\n",
      "$$$\n",
      "[['sports visualization', 'sports analytics'], '^^^^^^^^^^^']\n",
      "[[0.953217904653702], '@@@']\n",
      "0.953217904653702\n",
      "['sports visualization', 'sports analytics']\n",
      "$$$\n",
      "[['data storytelling', 'data driven storytelling'], '^^^^^^^^^^^']\n",
      "[[0.9672197344399888], '@@@']\n",
      "0.9672197344399888\n",
      "['data storytelling', 'data driven storytelling']\n",
      "$$$\n",
      "[['uncertainty visualisations', 'uncertainty visualization'], '^^^^^^^^^^^']\n",
      "[[0.9851706036761436], '@@@']\n",
      "0.9851706036761436\n",
      "['uncertainty visualisations', 'uncertainty visualization']\n",
      "$$$\n",
      "[['visualization', 'visualization grammar'], '^^^^^^^^^^^']\n",
      "[[0.9496353896872012], '@@@']\n",
      "0.9496353896872012\n",
      "['visualization', 'visualization grammar']\n",
      "$$$\n",
      "[['visualization', 'visualization grammar', 'visual analysis'], '^^^^^^^^^^^']\n",
      "[[0.9496353896872012, 0.9470225196864148, 0.9237037147350752], '@@@']\n",
      "0.9401205413695637\n",
      "['visual analysis', '()()()()()']\n",
      "['visualization', 'visualization grammar']\n",
      "$$$\n",
      "[['visualization', 'visualization grammar', 'visual reasoning'], '^^^^^^^^^^^']\n",
      "[[0.9496353896872012, 0.943873729964735, 0.925980485743651], '@@@']\n",
      "0.9398298684651958\n",
      "['visual reasoning', '()()()()()']\n",
      "['visualization', 'visualization grammar']\n",
      "$$$\n",
      "[['natural language interface', 'natural language understanding'], '^^^^^^^^^^^']\n",
      "[[0.9590822667777967], '@@@']\n",
      "0.9590822667777967\n",
      "['natural language interface', 'natural language understanding']\n",
      "$$$\n",
      "[['natural language interface', 'natural language understanding', 'natural language processing'], '^^^^^^^^^^^']\n",
      "[[0.9590822667777967, 0.9628636144546857, 0.9740721685843011], '@@@']\n",
      "0.9653393499389279\n",
      "['natural language interface', 'natural language understanding', 'natural language processing']\n",
      "$$$\n",
      "[['interactive visual analytics', 'interactive visual analysis'], '^^^^^^^^^^^']\n",
      "[[0.9797830354714948], '@@@']\n",
      "0.9797830354714948\n",
      "['interactive visual analytics', 'interactive visual analysis']\n",
      "$$$\n",
      "[['data visualization', 'printed data visualization'], '^^^^^^^^^^^']\n",
      "[[0.9586909081339058], '@@@']\n",
      "0.9586909081339058\n",
      "['data visualization', 'printed data visualization']\n",
      "$$$\n",
      "[['data visualization', 'printed data visualization', 'colormap data visualizations'], '^^^^^^^^^^^']\n",
      "[[0.9586909081339058, 0.9551623436119928, 0.9361394741023913], '@@@']\n",
      "0.9499975752827633\n",
      "['data visualization', 'printed data visualization', 'colormap data visualizations']\n",
      "$$$\n",
      "[['spatiotemporal dynamics', 'spatiotemporal visualization'], '^^^^^^^^^^^']\n",
      "[[0.9429442781273678], '@@@']\n",
      "0.9429442781273678\n",
      "['spatiotemporal dynamics', 'spatiotemporal visualization']\n",
      "$$$\n",
      "[['multivariate data'], '^^^^^^^^^^^']\n",
      "[[], '@@@']\n",
      "nan\n",
      "['multivariate data']\n",
      "$$$\n",
      "[['multivariate data', 'multivariate event sequence'], '^^^^^^^^^^^']\n",
      "[[0.932251382204974], '@@@']\n",
      "0.932251382204974\n",
      "['multivariate event sequence', '()()()()()']\n",
      "['multivariate data']\n",
      "$$$\n",
      "[['scientific data representation', 'scientific literature data'], '^^^^^^^^^^^']\n",
      "[[0.9582818929819286], '@@@']\n",
      "0.9582818929819286\n",
      "['scientific data representation', 'scientific literature data']\n",
      "$$$\n",
      "[['language modeling', 'language model adaptation'], '^^^^^^^^^^^']\n",
      "[[0.96598780916845], '@@@']\n",
      "0.96598780916845\n",
      "['language modeling', 'language model adaptation']\n",
      "$$$\n",
      "[['machine learning', 'interactive machine learning'], '^^^^^^^^^^^']\n",
      "[[0.9652128470307144], '@@@']\n",
      "0.9652128470307144\n",
      "['machine learning', 'interactive machine learning']\n",
      "$$$\n",
      "[['dashboards', 'dashboard'], '^^^^^^^^^^^']\n",
      "[[0.989691408251354], '@@@']\n",
      "0.989691408251354\n",
      "['dashboards', 'dashboard']\n",
      "$$$\n",
      "[['hypergraphs', 'hypergraph'], '^^^^^^^^^^^']\n",
      "[[0.9938652092710573], '@@@']\n",
      "0.9938652092710573\n",
      "['hypergraphs', 'hypergraph']\n",
      "$$$\n",
      "[['epidemiology', 'epidemiological modeling'], '^^^^^^^^^^^']\n",
      "[[0.9448914302185268], '@@@']\n",
      "0.9448914302185268\n",
      "['epidemiology', 'epidemiological modeling']\n",
      "$$$\n"
     ]
    }
   ],
   "source": [
    "openAI_embedds = json.load(open(r'../IEEE_papers/Result/openAI_embeddings.json'))\n",
    "cosine = json.load(open(r'../IEEE_papers/Result/cosine.json'))\n",
    "similarity_dict = {}\n",
    "check=[]\n",
    "for i in range(len(flat_list)):\n",
    "    similar = []\n",
    "    res= []\n",
    "    if (flat_list[i] not in check):\n",
    "        similar.append(flat_list[i])\n",
    "        check.append(flat_list[i])\n",
    "        avg_score = 0.0\n",
    "    for j in range(i+1,len(flat_list)):\n",
    "        score = calculate_cosine(openAI_embedds[flat_list[i]],openAI_embedds[flat_list[j]])\n",
    "        if (score>0.941 and flat_list[j] not in check or flat_list[i] not in check):\n",
    "            similar.append(flat_list[j])\n",
    "            check.append(flat_list[j])\n",
    "            # print([similar,\"^^^^^^^^^^^\"])\n",
    "            res = [calculate_cosine(openAI_embedds[a], openAI_embedds[b]) for idx, a in enumerate(similar) for b in similar[idx + 1:]]\n",
    "            print([res,\"@@@\"])\n",
    "            avg_score = np.mean(res,dtype=np.float64)\n",
    "            if(avg_score<0.941):\n",
    "                print([flat_list[j],\"()()()()()\"])\n",
    "                similar.remove(flat_list[j])\n",
    "            # print(similar)\n",
    "\n",
    "    similar = list(set(similar))\n",
    "    similar = \",\".join(similar)\n",
    "    check = list(set(check))\n",
    "    new_list = list(similar.split(\",\"))\n",
    "    if(len(new_list)>1):\n",
    "            mapping = map_listEntities(new_list)\n",
    "            similarity_dict[similar] = mapping.lower()\n",
    "save_json(similarity_dict, r'../IEEE_papers/Result/similarity_dict_2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "photosensitivity\n",
      "photosensitive epilepsy\n",
      "accessibility\n",
      "federated learning\n",
      "data heterogeneity\n",
      "cluster analysis\n",
      "declarative specification\n",
      "self service data transformation\n",
      "programming by example\n",
      "aesthetic pleasure\n",
      "aesthetics\n",
      "validated scale\n",
      "explainability\n",
      "neural network architecture search\n",
      "deep learning\n",
      "theory\n",
      "theoretical and empirical research\n",
      "qualitative study\n",
      "confidence intervals\n",
      "bar charts\n",
      "uncertainty\n",
      "hierarchical tabular data\n",
      "tabular visualization\n",
      "tabular data\n",
      "music mood classification\n",
      "ensemble learning\n",
      "time series visualization\n",
      "kirigami\n",
      "physicalization\n",
      "aesthetics\n",
      "traces\n",
      "parallel computing\n",
      "event sequence visualization\n",
      "equity\n",
      "deficit thinking\n",
      "storytelling\n",
      "augmented merge tree\n",
      "scalar field visualization\n",
      "pixel based visualization\n",
      "gaussian mixture models\n",
      "ray casting\n",
      "scientific visualization\n",
      "beliefs\n",
      "cognition\n",
      "motivated perception\n",
      "mathematics\n",
      "physical environmental sciences\n",
      "tracking transformation\n",
      "dendrograms\n",
      "cyber physical networks\n",
      "human centered computing\n",
      "molecular dynamics\n",
      "progressive analytics\n",
      "structure\n",
      "basketball tracking data\n",
      "off ball movement analysis\n",
      "sports visualization\n",
      "parallel coordinates chart\n",
      "data storytelling\n",
      "high dimensional data visualization\n",
      "takeaways\n",
      "annotation\n",
      "line charts\n",
      "gradient descent\n",
      "graph layout\n",
      "framework\n",
      "uncertainty visualisations\n",
      "data imputation\n",
      "missing values\n",
      "icon arrays\n",
      "cross language study\n",
      "visualization\n",
      "natural language interface\n",
      "natural language understanding\n",
      "visualization authoring\n",
      "semantic inference\n",
      "table comparison\n",
      "program understanding\n",
      "cultural heritage\n",
      "fragment reassembly\n",
      "immersive visualization\n",
      "iot\n",
      "racket sports\n",
      "training\n",
      "persistence\n",
      "stability\n",
      "merge trees\n",
      "genomics\n",
      "responsive visualization\n",
      "visualization grammar\n",
      "explainable ai\n",
      "concept activation vectors\n",
      "interactive visual analytics\n",
      "sports analytics\n",
      "embedded visualization\n",
      "data visualization\n",
      "constructionism\n",
      "children\n",
      "informal learning\n",
      "toolkits\n",
      "declarative specification\n",
      "animation\n",
      "pedagogy\n",
      "game interfaces\n",
      "final project\n",
      "regional industrial structure\n",
      "spatiotemporal dynamics\n",
      "multivariate time series\n",
      "treemaps\n",
      "data centric ai\n",
      "error analysis\n",
      "embedding projection\n",
      "explicit knowledge generation\n",
      "tabular data\n",
      "augmented reality\n",
      "tangible user interface\n",
      "printed data visualization\n",
      "narrative devices\n",
      "data driven storytelling\n",
      "interaction\n",
      "nvh analysis\n",
      "structure borne noise\n",
      "interactive visual analysis\n",
      "compensation\n",
      "treemaps\n",
      "stability\n",
      "workplace safety\n",
      "ergonomic assessment\n",
      "visual analysis\n",
      "lloyd relaxation\n",
      "dot plot\n",
      "kernel frequency estimation\n",
      "dimensionality reduction\n",
      "multidimensional scaling\n",
      "non linear projection\n",
      "contour\n",
      "multiclass visualization\n",
      "domain specific language\n",
      "colorization\n",
      "emd\n",
      "color concept association\n",
      "guidance theory\n",
      "guidance implementation\n",
      "self supervised learning\n",
      "data centric ai\n",
      "semantic segmentation\n",
      "latent space\n",
      "deep learning\n",
      "scientific data representation\n",
      "openalex\n",
      "author affiliation\n",
      "scientometric analysis\n",
      "surrogate modeling\n",
      "ensemble visualization\n",
      "parameter space exploration\n",
      "zero shot models\n",
      "language modeling\n",
      "natural language processing\n",
      "trajectories\n",
      "rendering\n",
      "multivariate data\n",
      "calibration\n",
      "reliability diagram\n",
      "model understanding\n",
      "analytic provenance\n",
      "benchmark study\n",
      "machine learning\n",
      "debiasing\n",
      "causality\n",
      "algorithmic fairness\n",
      "infoshield\n",
      "human trafficking\n",
      "labeling\n",
      "webcam\n",
      "time frequency\n",
      "multi scale\n",
      "ranking\n",
      "projection\n",
      "multi attribute data exploration\n",
      "sports analytics\n",
      "multivariate event sequence\n",
      "interactive pattern mining\n",
      "delta tracking\n",
      "path tracing\n",
      "ray tracing\n",
      "color cognition\n",
      "colormap data visualizations\n",
      "visual reasoning\n",
      "overdraw\n",
      "circle packing\n",
      "overlap free\n",
      "manifold learning\n",
      "dimensionality reduction\n",
      "human centered computing\n",
      "voronoi decomposition\n",
      "statistical summarization\n",
      "isosurfaces\n",
      "dashboards\n",
      "intent\n",
      "recommendations\n",
      "interpretability\n",
      "historical cohort analysis\n",
      "machine learning\n",
      "dashboards\n",
      "storytelling\n",
      "education\n",
      "spectral decomposition\n",
      "dynamic mode decomposition\n",
      "frequency based constraints\n",
      "situated analytics\n",
      "view layout\n",
      "immersive visualization\n",
      "data centric ai\n",
      "model validation\n",
      "data slicing\n",
      "declarative grammar\n",
      "natural language interface\n",
      "interactive exploration\n",
      "hypergraphs\n",
      "maps\n",
      "storyline visualization\n",
      "e commerce\n",
      "promotion strategy\n",
      "“what if” analysis\n",
      "mixed initiative exploration\n",
      "interaction recommendation\n",
      "visualization for public education\n",
      "quantum computing\n",
      "noise awareness\n",
      "data visualization\n",
      "epidemiology\n",
      "covid 19\n",
      "epidemiological modeling\n",
      "human machine cooperation\n",
      "interpolation\n",
      "visual storytelling\n",
      "genomics\n",
      "recommendation systems\n",
      "tasks\n",
      "bipartite\n",
      "network\n",
      "evaluation\n",
      "interdisciplinary experimental science\n",
      "scientific literature data\n",
      "interactive visual analysis\n",
      "idea generation\n",
      "interview study\n",
      "examples\n",
      "foveated rendering\n",
      "neural reconstruction\n",
      "deep learning\n",
      "hypergraph\n",
      "euler diagram\n",
      "integer linear programming\n",
      "covid 19\n",
      "line charts\n",
      "multiple forecast visualizations\n",
      "human ai interaction\n",
      "transfer learning\n",
      "interactive machine learning\n",
      "radio signal\n",
      "binary sequence\n",
      "visual abstraction\n",
      "electronic health record ehr \n",
      "medicine\n",
      "close distant reading\n",
      "metaphor\n",
      "machine learning\n",
      "glyph based visualization\n",
      "fiber surfaces\n",
      "and probability\n",
      "uncertainty visualization\n",
      "smart factory\n",
      "power plant visual analytics\n",
      "spatiotemporal visualization\n",
      "progressive culling\n",
      "output sensitivity\n",
      "multivariate attribute queries\n",
      "crowdsourcing\n",
      "gaze prediction\n",
      "webcam based eye tracking\n",
      "cardinality\n",
      "intent\n",
      "comparative constructions\n",
      "data hunches\n",
      "uncertainty\n",
      "data visualization\n",
      "adapter\n",
      "word embeddings\n",
      "language model adaptation\n",
      "sensemaking\n",
      "workflow summarization\n",
      "analytic provenance\n",
      "robotic arm\n",
      "haptic feedback\n",
      "human centred interaction\n",
      "crisis\n",
      "covid 19\n",
      "dashboard\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "mp = json.load(open(r'../IEEE_papers/Result/main_participants.json'))\n",
    "mp=mp[0:100]\n",
    "model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = True)\n",
    "embedds = {}\n",
    "serialized_dict = {}\n",
    "for dat in mp:\n",
    "    for i in dat:\n",
    "        input_text =  re.sub(\"\\s{2,}\", \" \", i)\n",
    "        input_text = input_text.lower()\n",
    "        print(input_text)\n",
    "        # print(type(i))\n",
    "        marked_text = \"[CLS] \" + input_text + \" [SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens_tensor, segments_tensors)\n",
    "            hidden_states = outputs[2]\n",
    "        token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "        token_vecs = hidden_states[-2][0]\n",
    "        sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "        # sentence_embedding = sentence_embedding.tolist()\n",
    "        embed_list = list(sentence_embedding)\n",
    "        # print(type(embed_list))\n",
    "        embedds[input_text]=embed_list\n",
    "for key, value in embedds.items():\n",
    "    ar = np.array(value)\n",
    "    serialized_dict[key] = ar.tolist()\n",
    "# embedds = [len(t) for t in embedds]\n",
    "save_json(serialized_dict, r'../IEEE_papers/Result/embed.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating tfdif scores for all author defined keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string \n",
    "import itertools\n",
    "\n",
    "dat = json.load(open(r'../IEEE_papers/processed_data/processed_data.json'))\n",
    "embedds = json.load(open(r'../IEEE_papers/Result/embed.json'))\n",
    "abstracts = []\n",
    "keywords = []\n",
    "scores = {}\n",
    "for index,datum in enumerate(dat):\n",
    "    abstract = datum['Abstract'].strip()\n",
    "    # print(abstract)\n",
    "    keyword= datum['AuthorKeywords'].strip()\n",
    "    keyword = keyword.replace(\"-\",\" \")\n",
    "    abstracts.append(abstract)\n",
    "    keywords.append(keyword)\n",
    "# save_json(abstracts, r'../IEEE_papers/Result/abs.json')\n",
    "save_json(keywords, r'../IEEE_papers/Result/keys.json')\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(abstracts)\n",
    "scores = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "\n",
    "keyword_scores = {}\n",
    "for datum in dat:\n",
    "    abstract = datum['Abstract'].strip()\n",
    "    keywords= datum['AuthorKeywords'].split(',')\n",
    "    keys_score = {} \n",
    "    for keys in keywords:\n",
    "        keys = replace_punctuation_with_whitespace(keys)\n",
    "        key = keys.split()\n",
    "        score=0.0\n",
    "        cnt=0\n",
    "        for k in key:\n",
    "            k = k.lower()\n",
    "            if k in scores.keys():\n",
    "                score += scores[k]\n",
    "                cnt+=1\n",
    "            else:\n",
    "                score = 10\n",
    "                cnt+=1\n",
    "        if(cnt!=0) :\n",
    "            score = score/cnt\n",
    "        keys_score[keys] = score\n",
    "    keyword_scores[abstract] = keys_score\n",
    "test = dict(itertools.islice(keyword_scores.items(), 10))\n",
    "save_json(keyword_scores, r'../IEEE_papers/Result/final_dict.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted average using tdidf score, only required when using BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat[0:20]\n",
    "temp=\"\"\n",
    "for datum in dat:\n",
    "    abstract = datum['Abstract'].strip()\n",
    "    keywords= datum['AuthorKeywords'].split(',')\n",
    "    for keys in keywords:\n",
    "        count = 0\n",
    "        for k in key:\n",
    "            count+=1\n",
    "            temp = \" \".join(k)\n",
    "            k = k.lower()\n",
    "            if k in scores.keys():\n",
    "                score += scores[k]\n",
    "                cnt+=1\n",
    "            else:\n",
    "                score = 10\n",
    "                cnt+=1\n",
    "        if(temp):\n",
    "            if(cnt!=0) :\n",
    "                score = score/cnt\n",
    "                embedds[temp]=embedds[temp]*score\n",
    "                embedds[temp]=np.mean(embedds[temp], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine score dictionary and getting top 'n' main participants using tfidf score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'electronic health record ehr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12800\\2833040590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mB\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\s+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mtup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mcosine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_cosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membedds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mcosine_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdatum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'electronic health record ehr'"
     ]
    }
   ],
   "source": [
    "chars = json.load(open(r'../IEEE_papers/Result/main_participants.json'))\n",
    "abs = json.load(open(r'../IEEE_papers/Result/abs.json'))\n",
    "embedds = json.load(open(r'../IEEE_papers/Result/embed.json'))\n",
    "chars = chars[0:100]\n",
    "top_n_values_per_key = {}\n",
    "cosine_scores = {}\n",
    "main_participants = []\n",
    "main = []\n",
    "for key, sub_dict in keyword_scores.items():\n",
    "    top_n_values = get_top_n_values(sub_dict, 3) # change number to change required main participants \n",
    "    main_participants.append(list(top_n_values.keys()))\n",
    "    top_n_values_per_key[key] = top_n_values\n",
    "for i in range(len(flat_list)):\n",
    "    for j in range(i+1,len(flat_list)):\n",
    "        rx = r'(?<=\\b[^\\W\\d_])\\s(?=[^\\W\\d_]\\b)'\n",
    "        A = flat_list[i].casefold()\n",
    "        A=re.sub(r'\\s+', ' ', A)\n",
    "        B = flat_list[j].casefold()\n",
    "        B=re.sub(r'\\s+', ' ', B)\n",
    "        tup = \",\".join([A,B])\n",
    "        cosine = calculate_cosine(embedds[A],embedds[B])\n",
    "        cosine_scores[tup] = cosine\n",
    "for i,datum in enumerate(chars):\n",
    "    res = [(a, b) for idx, a in enumerate(datum) for b in datum[idx + 1:]]\n",
    "    for index, word in enumerate(res):\n",
    "        if(index<len(datum)):\n",
    "            A = \"\".join(word[0])\n",
    "            A=A.lower().strip()\n",
    "            B = \"\".join(word[1])\n",
    "            B=B.lower().strip()\n",
    "            A=re.sub(r'\\s+', ' ', A)\n",
    "            B=re.sub(r'\\s+', ' ', B)\n",
    "            tupp = \",\".join([A,B])\n",
    "            cosine_sc = cosine_scores[tupp]\n",
    "            if(cosine_sc>0.821):\n",
    "                abst = abstracts[i]\n",
    "                ent_type = map_pairEntities(word[0],word[1])\n",
    "                if(word[0] in datum):\n",
    "                    datum.remove(word[0])\n",
    "                if(word[1] in datum):\n",
    "                    datum.remove(word[1])\n",
    "                datum.append(ent_type)\n",
    "    main.append(list(datum))\n",
    "save_json(main, r'../IEEE_papers/Result/test2.json')\n",
    "save_json(cosine_scores, r'../IEEE_papers/Result/cosine.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate similar words mapping using BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'photosensitivity,openalex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12800\\2503475117.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mtup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mflat_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflat_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[1;31m# print(type(tup))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                 \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.83\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mflat_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mflat_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                                 \u001b[1;31m# print(\"case 1\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'photosensitivity,openalex'"
     ]
    }
   ],
   "source": [
    "embedds = json.load(open(r'../IEEE_papers/Result/embed.json'))\n",
    "cosine_scores = json.load(open(r'../IEEE_papers/Result/cosine.json'))\n",
    "cosine_dict = {}\n",
    "check = []\n",
    "for i,datum in enumerate(flat_list):\n",
    "        similar = []\n",
    "        if (flat_list[i] not in check):\n",
    "                similar.append(flat_list[i])\n",
    "                check.append(flat_list[i])\n",
    "        # print(flat_list[i])\n",
    "        for j in range(i+1,len(flat_list)):\n",
    "                # print(type(flat_list[i]))\n",
    "                # print(flat_list[j])\n",
    "                tup = ','.join([flat_list[i],flat_list[j]])\n",
    "                # print(type(tup))\n",
    "                score = cosine_scores[tup]\n",
    "                if (score>0.83 and flat_list[j] not in check or flat_list[i] not in check):\n",
    "                                # print(\"case 1\")\n",
    "                                similar.append(flat_list[j])\n",
    "                                check.append(flat_list[j])\n",
    "                                # print(\"case 2\")\n",
    "                                # similar.append(flat_list[i])\n",
    "                                # check.append(flat_list[i])\n",
    "                                # # print(\"case 3\")\n",
    "                                # similar.append(flat_list[j])\n",
    "                                # check.append(flat_list[j])\n",
    "        similar = list(set(similar))\n",
    "        check = list(set(check))\n",
    "        print(similar)\n",
    "        print(\"$$$\")\n",
    "        post_removed = remove_keywords(similar)\n",
    "        post_removed.replace(\";\",\"\")\n",
    "        new_list = list(post_removed.split(\",\"))\n",
    "\n",
    "        if(len(new_list)>1):\n",
    "                mapping = map_listEntities(new_list)\n",
    "                cosine_dict[post_removed] = mapping.lower()\n",
    "save_json(cosine_dict, r'../IEEE_papers/Result/map_dict.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get final event graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "photosensitivity\n",
      "photosensitive epilepsy\n",
      "accessibility\n",
      "Federated learning\n",
      "data heterogeneity\n",
      "cluster analysis\n",
      "declarative specification\n",
      "self service data transformation\n",
      "programming by example\n",
      "aesthetic pleasure\n",
      "Aesthetics\n",
      "validated scale\n",
      "Explainability\n",
      "Neural Network Architecture Search\n",
      "Deep Learning\n",
      "Theory\n",
      "Theoretical and Empirical Research\n",
      "Qualitative Study\n",
      "Confidence intervals\n",
      "Bar charts\n",
      "Uncertainty\n",
      "hierarchical tabular data\n",
      "tabular visualization\n",
      "tabular data\n",
      "music mood classification\n",
      "ensemble learning\n",
      "time series visualization\n",
      "kirigami\n",
      "physicalization\n",
      "aesthetics\n",
      "traces\n",
      "parallel computing\n",
      "event sequence visualization\n",
      "Equity\n",
      "Deficit Thinking\n",
      "Storytelling\n",
      "augmented merge tree\n",
      "Scalar field visualization\n",
      "pixel based visualization\n",
      "Gaussian mixture models\n",
      "ray casting\n",
      "Scientific visualization\n",
      "Beliefs\n",
      "Cognition\n",
      "Motivated Perception\n",
      "Mathematics\n",
      "Physical   Environmental Sciences\n",
      "Tracking   Transformation\n",
      "Dendrograms\n",
      "Cyber physical networks\n",
      "Human centered computing\n",
      "Molecular dynamics\n",
      "progressive analytics\n",
      "structure\n",
      "basketball tracking data\n",
      "off ball movement analysis\n",
      "Sports visualization\n",
      "Parallel Coordinates Chart\n",
      "Data Storytelling\n",
      "High dimensional data visualization\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "def post_process_events(dataset):\n",
    "    for index, datum in enumerate(dataset):\n",
    "        events = []\n",
    "        main_characters = []\n",
    "        datum['doc_id'] = index\n",
    "        # datum['events_raw'] = datum['events']\n",
    "        events_str = datum['events'].split('\\n')\n",
    "        for chars in main_participants[index+1]:\n",
    "            print(chars)\n",
    "            main_characters.append(chars)\n",
    "        for event_str in events_str:\n",
    "            arguments=[]\n",
    "            event_str = event_str.strip()\n",
    "            components = event_str.split(':')\n",
    "            event_type = components[0].strip()\n",
    "            events.append({'Trigger':event_type, 'Main Participants': main_characters})\n",
    "        datum['events'] = events\n",
    "    return dataset\n",
    "\n",
    "dataset = json.load(open(r'../IEEE_papers/Events/events_merged.json'))\n",
    "processed_dataset = post_process_events(dataset)\n",
    "save_json(processed_dataset, r'../IEEE_papers/Result/final_participants.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
