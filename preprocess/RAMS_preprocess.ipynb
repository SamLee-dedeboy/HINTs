{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samytlee/opt/anaconda3/envs/event_hgraph_preprocess/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import networkx as nx\n",
    "import hypernetx as hnx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from refined.inference.processor import Refined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading /Users/samytlee/.cache/refined/wikipedia_model_with_numbers/model.pt: 100%|██████████| 724M/724M [02:16<00:00, 5.30MB/s] \n",
      "Downloading /Users/samytlee/.cache/refined/wikipedia_model_with_numbers/config.json: 100%|██████████| 658/658 [00:00<00:00, 2.54kB/s]\n",
      "Downloading /Users/samytlee/.cache/refined/wikipedia_model_with_numbers/precomputed_entity_descriptions_emb_wikipedia_6269457-300.np: 100%|██████████| 3.76G/3.76G [09:58<00:00, 6.29MB/s] \n",
      "Downloading /Users/samytlee/.cache/refined/roberta-base/pytorch_model.bin: 100%|██████████| 501M/501M [01:04<00:00, 7.76MB/s] \n",
      "Downloading /Users/samytlee/.cache/refined/roberta-base/config.json: 100%|██████████| 481/481 [00:00<00:00, 2.33kB/s]\n",
      "Downloading /Users/samytlee/.cache/refined/roberta-base/vocab.json: 100%|██████████| 899k/899k [00:01<00:00, 603kB/s]\n",
      "Downloading /Users/samytlee/.cache/refined/roberta-base/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 612kB/s]\n",
      "Downloading /Users/samytlee/.cache/refined/wikipedia_data/pem.lmdb: 100%|██████████| 1.42G/1.42G [03:00<00:00, 7.86MB/s]\n",
      "Downloading /Users/samytlee/.cache/refined/wikipedia_data/class_to_label.json: 100%|██████████| 49.8k/49.8k [00:00<00:00, 99.4kB/s]\n",
      "Downloading /Users/samytlee/.cache/refined/wikipedia_data/human_qcodes.json: 100%|██████████| 87.4M/87.4M [00:45<00:00, 1.93MB/s]\n",
      "Downloading /Users/samytlee/.cache/refined/wikipedia_data/class_to_idx.json: 100%|██████████| 23.2k/23.2k [00:00<00:00, 72.4kB/s]\n",
      "Downloading /Users/samytlee/.cache/refined/wikipedia_data/qcode_to_idx.lmdb: 100%|██████████| 238M/238M [00:50<00:00, 4.74MB/s] \n",
      "Downloading /Users/samytlee/.cache/refined/wikipedia_data/qcode_to_class_tns_6269457-138.np: 100%|██████████| 1.73G/1.73G [04:16<00:00, 6.74MB/s]\n",
      "Downloading /Users/samytlee/.cache/refined/wikipedia_data/subclasses.lmdb: 100%|██████████| 120M/120M [00:49<00:00, 2.39MB/s] \n",
      "Downloading /Users/samytlee/.cache/refined/wikipedia_data/qcode_to_wiki.lmdb: 100%|██████████| 580M/580M [01:52<00:00, 5.16MB/s] \n",
      "Downloading /Users/samytlee/.cache/refined/wikipedia_data/nltk_sentence_splitter_english.pickle: 100%|██████████| 407k/407k [00:01<00:00, 240kB/s]\n",
      "Some weights of the model checkpoint at /Users/samytlee/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /Users/samytlee/.cache/refined/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/samytlee/opt/anaconda3/envs/event_hgraph_preprocess/lib/python3.11/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "refined = Refined.from_pretrained(model_name='wikipedia_model_with_numbers',\n",
    "                                  entity_set=\"wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, filepath=r'new_data.json'):\n",
    "    with open(filepath, 'w') as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_reader = jsonlines.open(r'data/raw/RAMS/dev.jsonlines')\n",
    "test_reader = jsonlines.open(r'data/raw/RAMS/test.jsonlines')\n",
    "train_reader = jsonlines.open(r'data/raw/RAMS/train.jsonlines')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sentences(datum):\n",
    "    sentence_list = [\" \".join(sentence_word_list) for sentence_word_list in datum['sentences']] # merge the words into sentences\n",
    "    paragraph = \" \".join(sentence_list)\n",
    "    return paragraph\n",
    "\n",
    "def merge_events(datum):\n",
    "    words_flattened = [word for sentence in datum['sentences'] for word in sentence]\n",
    "    triggers = datum['evt_triggers']\n",
    "    trigger_type_dict = {}\n",
    "    for trigger_datum in triggers:\n",
    "        trigger_span = trigger_datum[:2]\n",
    "        trigger_word = \" \".join(words_flattened[trigger_span[0]:trigger_span[1]+1])\n",
    "        trigger_type = trigger_datum[2][0][0]\n",
    "        trigger_type_dict[trigger_word] = trigger_type\n",
    "    links = datum['gold_evt_links']\n",
    "    events = {}\n",
    "    for link in links:\n",
    "        trigger_span = link[0] # a list of [start, end]\n",
    "        trigger_word = \" \".join(words_flattened[trigger_span[0]:trigger_span[1]+1]) # a string\n",
    "        argument_span = link[1] # a list of [start, end]\n",
    "        argument_word = \" \".join(words_flattened[argument_span[0]:argument_span[1]+1]) # a string\n",
    "        argument_role = link[2] # a string\n",
    "        trigger_type = trigger_type_dict[trigger_word]\n",
    "        if trigger_word not in events.keys():\n",
    "            events[trigger_word] = {\n",
    "                \"trigger\": trigger_word,\n",
    "                \"trigger_span\": trigger_span,\n",
    "                \"trigger_type\": trigger_type,\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_id\": argument_word,\n",
    "                        \"argument_word\": argument_word,\n",
    "                        \"argument_role\": argument_role,\n",
    "                        \"argument_span\": argument_span\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        else:\n",
    "            events[trigger_word]['arguments'].append({\n",
    "                \"argument_id\": argument_word,\n",
    "                \"argument_word\": argument_word,\n",
    "                \"argument_role\": argument_role,\n",
    "                \"argument_span\": argument_span\n",
    "            })\n",
    "    return list(events.values())\n",
    "\n",
    "def link_entities(events, paragraph):\n",
    "    spans = refined.process_text(paragraph)\n",
    "    for span in spans:\n",
    "        entity_word = span.text\n",
    "        for event in events:\n",
    "            for argument in event['arguments']:\n",
    "                if argument['argument_word'] == entity_word:\n",
    "                    if span.predicted_entity != None and span.predicted_entity.wikidata_entity_id != None:\n",
    "                        entity_id = span.predicted_entity.wikidata_entity_id\n",
    "                        entity_title = span.predicted_entity.wikipedia_entity_title\n",
    "                        argument['argument_id'] = entity_id\n",
    "                        argument['entity_title'] = entity_title\n",
    "                    argument['entity_type'] = span.coarse_mention_type\n",
    "    return events\n",
    "\n",
    "def transform_dataset(dataset):\n",
    "    transformed_dataset = {}\n",
    "    for index, datum in enumerate(dataset):\n",
    "        print(\"{}/{}\".format(index, len(dataset)))\n",
    "        paragraph = merge_sentences(datum)\n",
    "        events = merge_events(datum)\n",
    "        if events == []: continue\n",
    "        events = link_entities(events, paragraph)\n",
    "        doc_key = datum['doc_key']\n",
    "        source_url = datum['source_url']\n",
    "        if doc_key not in transformed_dataset.keys():\n",
    "            transformed_dataset[doc_key] = {\n",
    "                \"doc_id\": doc_key,\n",
    "                \"source_url\": source_url,\n",
    "                \"events\": []\n",
    "            }\n",
    "        transformed_dataset[doc_key]['events'] += events\n",
    "    return list(transformed_dataset.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samytlee/opt/anaconda3/envs/event_hgraph_preprocess/lib/python3.11/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'trigger': 'confiscated', 'trigger_span': [58, 58], 'trigger_type': 'transaction.transaction.n/a', 'arguments': [{'argument_id': 'Tahir Javed', 'argument_word': 'Tahir Javed', 'argument_role': 'evt130arg01participant', 'argument_span': [48, 49], 'entity_type': 'PERSON'}, {'argument_id': 'Q173', 'argument_word': 'Alabama', 'argument_role': 'evt130arg04place', 'argument_span': [44, 44], 'entity_title': 'Alabama', 'entity_type': 'GPE'}]}]\n"
     ]
    }
   ],
   "source": [
    "dev_reader = jsonlines.open(r'data/raw/RAMS/dev.jsonlines')\n",
    "for datum in dev_reader:\n",
    "    doc_id = datum['doc_key']\n",
    "    if doc_id == \"nw_RC0da9ca01673da1e2a47f6ccf9d239cbde98f30122f50c5ced8fa4743\":\n",
    "        paragraph = merge_sentences(datum)\n",
    "        events = merge_events(datum)\n",
    "        events = link_entities(events, paragraph)\n",
    "        print(events)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/878\n",
      "1/878\n",
      "2/878\n",
      "3/878\n",
      "4/878\n",
      "5/878\n",
      "6/878\n",
      "7/878\n",
      "8/878\n",
      "9/878\n",
      "10/878\n",
      "11/878\n",
      "12/878\n",
      "13/878\n",
      "14/878\n",
      "15/878\n",
      "16/878\n",
      "17/878\n",
      "18/878\n",
      "19/878\n",
      "20/878\n",
      "21/878\n",
      "22/878\n",
      "23/878\n",
      "24/878\n",
      "25/878\n",
      "26/878\n",
      "27/878\n",
      "28/878\n",
      "29/878\n",
      "30/878\n",
      "31/878\n",
      "32/878\n",
      "33/878\n",
      "34/878\n",
      "35/878\n",
      "36/878\n",
      "37/878\n",
      "38/878\n",
      "39/878\n",
      "40/878\n",
      "41/878\n",
      "42/878\n",
      "43/878\n",
      "44/878\n",
      "45/878\n",
      "46/878\n",
      "47/878\n",
      "48/878\n",
      "49/878\n",
      "50/878\n",
      "51/878\n",
      "52/878\n",
      "53/878\n",
      "54/878\n",
      "55/878\n",
      "56/878\n",
      "57/878\n",
      "58/878\n",
      "59/878\n",
      "60/878\n",
      "61/878\n",
      "62/878\n",
      "63/878\n",
      "64/878\n",
      "65/878\n",
      "66/878\n",
      "67/878\n",
      "68/878\n",
      "69/878\n",
      "70/878\n",
      "71/878\n",
      "72/878\n",
      "73/878\n",
      "74/878\n",
      "75/878\n",
      "76/878\n",
      "77/878\n",
      "78/878\n",
      "79/878\n",
      "80/878\n",
      "81/878\n",
      "82/878\n",
      "83/878\n",
      "84/878\n",
      "85/878\n",
      "86/878\n",
      "87/878\n",
      "88/878\n",
      "89/878\n",
      "90/878\n",
      "91/878\n",
      "92/878\n",
      "93/878\n",
      "94/878\n",
      "95/878\n",
      "96/878\n",
      "97/878\n",
      "98/878\n",
      "99/878\n",
      "100/878\n",
      "101/878\n",
      "102/878\n",
      "103/878\n",
      "104/878\n",
      "105/878\n",
      "106/878\n",
      "107/878\n",
      "108/878\n",
      "109/878\n",
      "110/878\n",
      "111/878\n",
      "112/878\n",
      "113/878\n",
      "114/878\n",
      "115/878\n",
      "116/878\n",
      "117/878\n",
      "118/878\n",
      "119/878\n",
      "120/878\n",
      "121/878\n",
      "122/878\n",
      "123/878\n",
      "124/878\n",
      "125/878\n",
      "126/878\n",
      "127/878\n",
      "128/878\n",
      "129/878\n",
      "130/878\n",
      "131/878\n",
      "132/878\n",
      "133/878\n",
      "134/878\n",
      "135/878\n",
      "136/878\n",
      "137/878\n",
      "138/878\n",
      "139/878\n",
      "140/878\n",
      "141/878\n",
      "142/878\n",
      "143/878\n",
      "144/878\n",
      "145/878\n",
      "146/878\n",
      "147/878\n",
      "148/878\n",
      "149/878\n",
      "150/878\n",
      "151/878\n",
      "152/878\n",
      "153/878\n",
      "154/878\n",
      "155/878\n",
      "156/878\n",
      "157/878\n",
      "158/878\n",
      "159/878\n",
      "160/878\n",
      "161/878\n",
      "162/878\n",
      "163/878\n",
      "164/878\n",
      "165/878\n",
      "166/878\n",
      "167/878\n",
      "168/878\n",
      "169/878\n",
      "170/878\n",
      "171/878\n",
      "172/878\n",
      "173/878\n",
      "174/878\n",
      "175/878\n",
      "176/878\n",
      "177/878\n",
      "178/878\n",
      "179/878\n",
      "180/878\n",
      "181/878\n",
      "182/878\n",
      "183/878\n",
      "184/878\n",
      "185/878\n",
      "186/878\n",
      "187/878\n",
      "188/878\n",
      "189/878\n",
      "190/878\n",
      "191/878\n",
      "192/878\n",
      "193/878\n",
      "194/878\n",
      "195/878\n",
      "196/878\n",
      "197/878\n",
      "198/878\n",
      "199/878\n",
      "200/878\n",
      "201/878\n",
      "202/878\n",
      "203/878\n",
      "204/878\n",
      "205/878\n",
      "206/878\n",
      "207/878\n",
      "208/878\n",
      "209/878\n",
      "210/878\n",
      "211/878\n",
      "212/878\n",
      "213/878\n",
      "214/878\n",
      "215/878\n",
      "216/878\n",
      "217/878\n",
      "218/878\n",
      "219/878\n",
      "220/878\n",
      "221/878\n",
      "222/878\n",
      "223/878\n",
      "224/878\n",
      "225/878\n",
      "226/878\n",
      "227/878\n",
      "228/878\n",
      "229/878\n",
      "230/878\n",
      "231/878\n",
      "232/878\n",
      "233/878\n",
      "234/878\n",
      "235/878\n",
      "236/878\n",
      "237/878\n",
      "238/878\n",
      "239/878\n",
      "240/878\n",
      "241/878\n",
      "242/878\n",
      "243/878\n",
      "244/878\n",
      "245/878\n",
      "246/878\n",
      "247/878\n",
      "248/878\n",
      "249/878\n",
      "250/878\n",
      "251/878\n",
      "252/878\n",
      "253/878\n",
      "254/878\n",
      "255/878\n",
      "256/878\n",
      "257/878\n",
      "258/878\n",
      "259/878\n",
      "260/878\n",
      "261/878\n",
      "262/878\n",
      "263/878\n",
      "264/878\n",
      "265/878\n",
      "266/878\n",
      "267/878\n",
      "268/878\n",
      "269/878\n",
      "270/878\n",
      "271/878\n",
      "272/878\n",
      "273/878\n",
      "274/878\n",
      "275/878\n",
      "276/878\n",
      "277/878\n",
      "278/878\n",
      "279/878\n",
      "280/878\n",
      "281/878\n",
      "282/878\n",
      "283/878\n",
      "284/878\n",
      "285/878\n",
      "286/878\n",
      "287/878\n",
      "288/878\n",
      "289/878\n",
      "290/878\n",
      "291/878\n",
      "292/878\n",
      "293/878\n",
      "294/878\n",
      "295/878\n",
      "296/878\n",
      "297/878\n",
      "298/878\n",
      "299/878\n",
      "300/878\n",
      "301/878\n",
      "302/878\n",
      "303/878\n",
      "304/878\n",
      "305/878\n",
      "306/878\n",
      "307/878\n",
      "308/878\n",
      "309/878\n",
      "310/878\n",
      "311/878\n",
      "312/878\n",
      "313/878\n",
      "314/878\n",
      "315/878\n",
      "316/878\n",
      "317/878\n",
      "318/878\n",
      "319/878\n",
      "320/878\n",
      "321/878\n",
      "322/878\n",
      "323/878\n",
      "324/878\n",
      "325/878\n",
      "326/878\n",
      "327/878\n",
      "328/878\n",
      "329/878\n",
      "330/878\n",
      "331/878\n",
      "332/878\n",
      "333/878\n",
      "334/878\n",
      "335/878\n",
      "336/878\n",
      "337/878\n",
      "338/878\n",
      "339/878\n",
      "340/878\n",
      "341/878\n",
      "342/878\n",
      "343/878\n",
      "344/878\n",
      "345/878\n",
      "346/878\n",
      "347/878\n",
      "348/878\n",
      "349/878\n",
      "350/878\n",
      "351/878\n",
      "352/878\n",
      "353/878\n",
      "354/878\n",
      "355/878\n",
      "356/878\n",
      "357/878\n",
      "358/878\n",
      "359/878\n",
      "360/878\n",
      "361/878\n",
      "362/878\n",
      "363/878\n",
      "364/878\n",
      "365/878\n",
      "366/878\n",
      "367/878\n",
      "368/878\n",
      "369/878\n",
      "370/878\n",
      "371/878\n",
      "372/878\n",
      "373/878\n",
      "374/878\n",
      "375/878\n",
      "376/878\n",
      "377/878\n",
      "378/878\n",
      "379/878\n",
      "380/878\n",
      "381/878\n",
      "382/878\n",
      "383/878\n",
      "384/878\n",
      "385/878\n",
      "386/878\n",
      "387/878\n",
      "388/878\n",
      "389/878\n",
      "390/878\n",
      "391/878\n",
      "392/878\n",
      "393/878\n",
      "394/878\n",
      "395/878\n",
      "396/878\n",
      "397/878\n",
      "398/878\n",
      "399/878\n",
      "400/878\n",
      "401/878\n",
      "402/878\n",
      "403/878\n",
      "404/878\n",
      "405/878\n",
      "406/878\n",
      "407/878\n",
      "408/878\n",
      "409/878\n",
      "410/878\n",
      "411/878\n",
      "412/878\n",
      "413/878\n",
      "414/878\n",
      "415/878\n",
      "416/878\n",
      "417/878\n",
      "418/878\n",
      "419/878\n",
      "420/878\n",
      "421/878\n",
      "422/878\n",
      "423/878\n",
      "424/878\n",
      "425/878\n",
      "426/878\n",
      "427/878\n",
      "428/878\n",
      "429/878\n",
      "430/878\n",
      "431/878\n",
      "432/878\n",
      "433/878\n",
      "434/878\n",
      "435/878\n",
      "436/878\n",
      "437/878\n",
      "438/878\n",
      "439/878\n",
      "440/878\n",
      "441/878\n",
      "442/878\n",
      "443/878\n",
      "444/878\n",
      "445/878\n",
      "446/878\n",
      "447/878\n",
      "448/878\n",
      "449/878\n",
      "450/878\n",
      "451/878\n",
      "452/878\n",
      "453/878\n",
      "454/878\n",
      "455/878\n",
      "456/878\n",
      "457/878\n",
      "458/878\n",
      "459/878\n",
      "460/878\n",
      "461/878\n",
      "462/878\n",
      "463/878\n",
      "464/878\n",
      "465/878\n",
      "466/878\n",
      "467/878\n",
      "468/878\n",
      "469/878\n",
      "470/878\n",
      "471/878\n",
      "472/878\n",
      "473/878\n",
      "474/878\n",
      "475/878\n",
      "476/878\n",
      "477/878\n",
      "478/878\n",
      "479/878\n",
      "480/878\n",
      "481/878\n",
      "482/878\n",
      "483/878\n",
      "484/878\n",
      "485/878\n",
      "486/878\n",
      "487/878\n",
      "488/878\n",
      "489/878\n",
      "490/878\n",
      "491/878\n",
      "492/878\n",
      "493/878\n",
      "494/878\n",
      "495/878\n",
      "496/878\n",
      "497/878\n",
      "498/878\n",
      "499/878\n",
      "500/878\n",
      "501/878\n",
      "502/878\n",
      "503/878\n",
      "504/878\n",
      "505/878\n",
      "506/878\n",
      "507/878\n",
      "508/878\n",
      "509/878\n",
      "510/878\n",
      "511/878\n",
      "512/878\n",
      "513/878\n",
      "514/878\n",
      "515/878\n",
      "516/878\n",
      "517/878\n",
      "518/878\n",
      "519/878\n",
      "520/878\n",
      "521/878\n",
      "522/878\n",
      "523/878\n",
      "524/878\n",
      "525/878\n",
      "526/878\n",
      "527/878\n",
      "528/878\n",
      "529/878\n",
      "530/878\n",
      "531/878\n",
      "532/878\n",
      "533/878\n",
      "534/878\n",
      "535/878\n",
      "536/878\n",
      "537/878\n",
      "538/878\n",
      "539/878\n",
      "540/878\n",
      "541/878\n",
      "542/878\n",
      "543/878\n",
      "544/878\n",
      "545/878\n",
      "546/878\n",
      "547/878\n",
      "548/878\n",
      "549/878\n",
      "550/878\n",
      "551/878\n",
      "552/878\n",
      "553/878\n",
      "554/878\n",
      "555/878\n",
      "556/878\n",
      "557/878\n",
      "558/878\n",
      "559/878\n",
      "560/878\n",
      "561/878\n",
      "562/878\n",
      "563/878\n",
      "564/878\n",
      "565/878\n",
      "566/878\n",
      "567/878\n",
      "568/878\n",
      "569/878\n",
      "570/878\n",
      "571/878\n",
      "572/878\n",
      "573/878\n",
      "574/878\n",
      "575/878\n",
      "576/878\n",
      "577/878\n",
      "578/878\n",
      "579/878\n",
      "580/878\n",
      "581/878\n",
      "582/878\n",
      "583/878\n",
      "584/878\n",
      "585/878\n",
      "586/878\n",
      "587/878\n",
      "588/878\n",
      "589/878\n",
      "590/878\n",
      "591/878\n",
      "592/878\n",
      "593/878\n",
      "594/878\n",
      "595/878\n",
      "596/878\n",
      "597/878\n",
      "598/878\n",
      "599/878\n",
      "600/878\n",
      "601/878\n",
      "602/878\n",
      "603/878\n",
      "604/878\n",
      "605/878\n",
      "606/878\n",
      "607/878\n",
      "608/878\n",
      "609/878\n",
      "610/878\n",
      "611/878\n",
      "612/878\n",
      "613/878\n",
      "614/878\n",
      "615/878\n",
      "616/878\n",
      "617/878\n",
      "618/878\n",
      "619/878\n",
      "620/878\n",
      "621/878\n",
      "622/878\n",
      "623/878\n",
      "624/878\n",
      "625/878\n",
      "626/878\n",
      "627/878\n",
      "628/878\n",
      "629/878\n",
      "630/878\n",
      "631/878\n",
      "632/878\n",
      "633/878\n",
      "634/878\n",
      "635/878\n",
      "636/878\n",
      "637/878\n",
      "638/878\n",
      "639/878\n",
      "640/878\n",
      "641/878\n",
      "642/878\n",
      "643/878\n",
      "644/878\n",
      "645/878\n",
      "646/878\n",
      "647/878\n",
      "648/878\n",
      "649/878\n",
      "650/878\n",
      "651/878\n",
      "652/878\n",
      "653/878\n",
      "654/878\n",
      "655/878\n",
      "656/878\n",
      "657/878\n",
      "658/878\n",
      "659/878\n",
      "660/878\n",
      "661/878\n",
      "662/878\n",
      "663/878\n",
      "664/878\n",
      "665/878\n",
      "666/878\n",
      "667/878\n",
      "668/878\n",
      "669/878\n",
      "670/878\n",
      "671/878\n",
      "672/878\n",
      "673/878\n",
      "674/878\n",
      "675/878\n",
      "676/878\n",
      "677/878\n",
      "678/878\n",
      "679/878\n",
      "680/878\n",
      "681/878\n",
      "682/878\n",
      "683/878\n",
      "684/878\n",
      "685/878\n",
      "686/878\n",
      "687/878\n",
      "688/878\n",
      "689/878\n",
      "690/878\n",
      "691/878\n",
      "692/878\n",
      "693/878\n",
      "694/878\n",
      "695/878\n",
      "696/878\n",
      "697/878\n",
      "698/878\n",
      "699/878\n",
      "700/878\n",
      "701/878\n",
      "702/878\n",
      "703/878\n",
      "704/878\n",
      "705/878\n",
      "706/878\n",
      "707/878\n",
      "708/878\n",
      "709/878\n",
      "710/878\n",
      "711/878\n",
      "712/878\n",
      "713/878\n",
      "714/878\n",
      "715/878\n",
      "716/878\n",
      "717/878\n",
      "718/878\n",
      "719/878\n",
      "720/878\n",
      "721/878\n",
      "722/878\n",
      "723/878\n",
      "724/878\n",
      "725/878\n",
      "726/878\n",
      "727/878\n",
      "728/878\n",
      "729/878\n",
      "730/878\n",
      "731/878\n",
      "732/878\n",
      "733/878\n",
      "734/878\n",
      "735/878\n",
      "736/878\n",
      "737/878\n",
      "738/878\n",
      "739/878\n",
      "740/878\n",
      "741/878\n",
      "742/878\n",
      "743/878\n",
      "744/878\n",
      "745/878\n",
      "746/878\n",
      "747/878\n",
      "748/878\n",
      "749/878\n",
      "750/878\n",
      "751/878\n",
      "752/878\n",
      "753/878\n",
      "754/878\n",
      "755/878\n",
      "756/878\n",
      "757/878\n",
      "758/878\n",
      "759/878\n",
      "760/878\n",
      "761/878\n",
      "762/878\n",
      "763/878\n",
      "764/878\n",
      "765/878\n",
      "766/878\n",
      "767/878\n",
      "768/878\n",
      "769/878\n",
      "770/878\n",
      "771/878\n",
      "772/878\n",
      "773/878\n",
      "774/878\n",
      "775/878\n",
      "776/878\n",
      "777/878\n",
      "778/878\n",
      "779/878\n",
      "780/878\n",
      "781/878\n",
      "782/878\n",
      "783/878\n",
      "784/878\n",
      "785/878\n",
      "786/878\n",
      "787/878\n",
      "788/878\n",
      "789/878\n",
      "790/878\n",
      "791/878\n",
      "792/878\n",
      "793/878\n",
      "794/878\n",
      "795/878\n",
      "796/878\n",
      "797/878\n",
      "798/878\n",
      "799/878\n",
      "800/878\n",
      "801/878\n",
      "802/878\n",
      "803/878\n",
      "804/878\n",
      "805/878\n",
      "806/878\n",
      "807/878\n",
      "808/878\n",
      "809/878\n",
      "810/878\n",
      "811/878\n",
      "812/878\n",
      "813/878\n",
      "814/878\n",
      "815/878\n",
      "816/878\n",
      "817/878\n",
      "818/878\n",
      "819/878\n",
      "820/878\n",
      "821/878\n",
      "822/878\n",
      "823/878\n",
      "824/878\n",
      "825/878\n",
      "826/878\n",
      "827/878\n",
      "828/878\n",
      "829/878\n",
      "830/878\n",
      "831/878\n",
      "832/878\n",
      "833/878\n",
      "834/878\n",
      "835/878\n",
      "836/878\n",
      "837/878\n",
      "838/878\n",
      "839/878\n",
      "840/878\n",
      "841/878\n",
      "842/878\n",
      "843/878\n",
      "844/878\n",
      "845/878\n",
      "846/878\n",
      "847/878\n",
      "848/878\n",
      "849/878\n",
      "850/878\n",
      "851/878\n",
      "852/878\n",
      "853/878\n",
      "854/878\n",
      "855/878\n",
      "856/878\n",
      "857/878\n",
      "858/878\n",
      "859/878\n",
      "860/878\n",
      "861/878\n",
      "862/878\n",
      "863/878\n",
      "864/878\n",
      "865/878\n",
      "866/878\n",
      "867/878\n",
      "868/878\n",
      "869/878\n",
      "870/878\n",
      "871/878\n",
      "872/878\n",
      "873/878\n",
      "874/878\n",
      "875/878\n",
      "876/878\n",
      "877/878\n"
     ]
    }
   ],
   "source": [
    "# dataset = [datum for datum in dev_reader] + [datum for datum in test_reader] + [datum for datum in train_reader]\n",
    "dataset = [datum for datum in dev_reader]\n",
    "transformed_dataset = transform_dataset(dataset)\n",
    "save_json(transformed_dataset, r'data/result/RAMS/events.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguate(docs):\n",
    "    nodes_dict = {}\n",
    "    hyper_edges_dict = {}\n",
    "    links = []\n",
    "    for doc in docs:\n",
    "        doc_id = doc['doc_id']\n",
    "        doc_url = doc['source_url']\n",
    "        for event in doc['events']:\n",
    "            arguments = event['arguments']\n",
    "            # create an entity node for each argument\n",
    "            for argument in arguments:\n",
    "                argument_id = argument['argument_id']\n",
    "                argument_word = argument['argument_word']\n",
    "                argument_title = argument['entity_title'] if 'entity_title' in argument else argument_word\n",
    "                argument_entity_type = argument['entity_type'] if 'entity_type' in argument else \"None\"\n",
    "                argument_span = argument['argument_span']\n",
    "                argument_role = argument['argument_role']\n",
    "                if argument_id not in nodes_dict.keys():\n",
    "                    nodes_dict[argument_id] = {\n",
    "                        \"id\": argument_id, \n",
    "                        \"title\": argument_title,\n",
    "                        \"entity_type\": argument_entity_type,\n",
    "                        \"type\": \"entity\",\n",
    "                        \"argument_role\": argument_role,\n",
    "                        \"mentions\": [\n",
    "                            {\n",
    "                                \"doc_id\": doc_id,\n",
    "                                \"mention\": argument_word,\n",
    "                                \"span\": {'start': argument_span[0], 'end': argument_span[1]}\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                else:\n",
    "                    nodes_dict[argument_id]['mentions'].append(\n",
    "                        {\n",
    "                            \"doc_id\": doc_id,\n",
    "                            \"mention\": argument_word,\n",
    "                            \"span\": {'start': argument_span[0], 'end': argument_span[1]}\n",
    "                        }\n",
    "                    )\n",
    "            argument_ids = [argument['argument_id'] for argument in arguments]\n",
    "            if any([argument_id == None for argument_id in argument_ids]):\n",
    "                print(doc_id, argument_ids)\n",
    "            sorted_argument_ids = sorted(argument_ids)\n",
    "            # create hyperedge \n",
    "            trigger_id = event['trigger'] # TODO: add disambiguation\n",
    "            trigger_type = event['trigger_type']\n",
    "            hyper_edge_id = trigger_id  + \"-\" + \"-\".join(sorted_argument_ids)\n",
    "            if hyper_edge_id not in hyper_edges_dict.keys():\n",
    "                hyper_edges_dict[hyper_edge_id] = {\n",
    "                    'id': hyper_edge_id,\n",
    "                    'type': \"hyper_edge\",\n",
    "                    \"trigger\": trigger_id,\n",
    "                    \"trigger_type\": trigger_type,\n",
    "                    \"arguments\": sorted_argument_ids,\n",
    "                    \"mentions\": [\n",
    "                        {\n",
    "                            \"doc_id\": doc_id,\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            else:\n",
    "                hyper_edges_dict[hyper_edge_id]['mentions'].append(\n",
    "                    {\n",
    "                        \"doc_id\": doc_id\n",
    "                    }\n",
    "                )\n",
    "            for argument_id in argument_ids:\n",
    "                links.append((hyper_edge_id, argument_id))\n",
    "    return nodes_dict, hyper_edges_dict, links\n",
    "\n",
    "def merge_RAMS(dataset):\n",
    "    nodes_dict, hyper_edges_dict, links = disambiguate(dataset)\n",
    "    B = nx.Graph()\n",
    "    B.add_nodes_from(list(hyper_edges_dict.keys()), bipartite=0)\n",
    "    B.add_nodes_from(list(nodes_dict.keys()), bipartite=1)\n",
    "    B.add_edges_from(links)\n",
    "    return hnx.Hypergraph.from_bipartite(B), nodes_dict, hyper_edges_dict, links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1239, 834]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H, nodes_dict, hyper_edges_dict, links = merge_RAMS(transformed_dataset)\n",
    "list(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_degree_distribution(HG, fit_line=False):\n",
    "    degree_sequence = [HG.degree(node) for node in HG.nodes]\n",
    "    degree_counts = [(degree, degree_sequence.count(degree)) for degree in set(degree_sequence)]\n",
    "    x, y = zip(*degree_counts)\n",
    "        \n",
    "    # fit line\n",
    "    if fit_line:\n",
    "        filter_degree = 15\n",
    "        filtered_degree_sequence = list(filter(lambda degree: degree < filter_degree, degree_sequence))\n",
    "        filtered_degree_counts = [(degree, degree_sequence.count(degree)) for degree in set(filtered_degree_sequence)]\n",
    "        filtered_x, filtered_y = zip(*filtered_degree_counts)\n",
    "        log_x = np.log10(filtered_x)\n",
    "        log_y = np.log10(filtered_y)\n",
    "        slope, intercept = np.polyfit(log_x, log_y, 1)\n",
    "        print(\"slope:\", slope, \"intercept:\", intercept)\n",
    "        x_vals = np.array([min(filtered_x), max(filtered_x)])\n",
    "        y_vals = 10**(intercept + slope*np.log10(x_vals))\n",
    "        plt.plot(x_vals, y_vals, '--')\n",
    "    \n",
    "        \n",
    "    plt.scatter(x, y)\n",
    "    # plt.xscale(\"log\")\n",
    "    # plt.yscale(\"log\")\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food or clothes', 'World War II', 'one', 'a coffin', 'these ties', 'nuclear weapons', 'Sunni groups', 'thousands of criminal aliens', '$ 1.7 billion', 'demolition', 'real estate empire', 'government agencies', 'Iraqis', 'Little Rock hotel room', 'wooden shack', 'Ottoman Turks', 'Syrian opposition', 'viewers and listeners', 'Trump', 'the rebels', 'you', 'CrowdStrike', 'Mrs Clinton', 'nominee', 'Italy and Germany', 'buildings', 'U.S. warplanes', 'Christians', 'Levitan', 'Obama DHS chief', 'Reuters', '25,000 Chinese', 'Al Qaeda', 'Mrs Clinton or her aides', 'commercial activities', 'countries', 'the public', 'demolition contractor', 'New Democrats', 'loans', \"the ' babies '\", 'outside groups', 'Ted', '@WIStateFair', 'political parties', 'Two undercover videos', 'Bill Clinton', 'Kenya', 'an illegal', 'donations', '$ 2,700 to his campaign and $ 25,000', 'Political Vindication Radio', 'secret ledgers', 'Jeh Johnson', 'Saudi Arabia', 'Cornel West', 'mother', 'America', 'Mrs. Clinton', 'Shaar', 'non - nuclear countries', 'Ukrainian snipers', 'battleships', 'apparatus', 'American aircraft', '$ 4 million', 'black player from Czech Republic', 'foreign leaders and diplomats', 'Trump ’s fitness for the office', 'brothers', 'violating fiscal laws', 'progressive and young voters', 'forces', 'Turkmen Mountain', 'top cop', 'Moscow', 'Iraqi troops', 'other countries', 'foreign intelligence snoops', 'terrorists', 'capability', 'Greek airspace', 'Obama', 'the bureau', 'tankers', 'DNC', 'soliciting a minor for prostitution', 'the 13-year - old', 'presidential election', 'two Iraqis , one Tunisian , one Chinese , one Iranian , one Ukrainian , one Jordanian and one person from Uzbekistan', 'WHO', 'U.N. Security Council', 'young man', 'the employees', 'The Associated Press ’ Twitter account', 'these parties', 'Anton Erygin', 'ports', 'Kremlin', 'Tumblr', 'Fox & Friends', 'Google', 'atomic bomb', 'Russian authorities', 'rebel', 'cargo ship', 'husband', 'Barbara Boxer', 'we', 'Roman Roslovtsev', '89 people', 'IOC', 'Flower Branch Apartments', 'Russia or its ally', 'Christie ’s , the esteemed New York City auction house', 'Google employee', 'France', 'east of the Euphrates', 'Here', 'U.S. special operations forces', 'Singapore', 'Saudi embassy', 'a dozen Palestine solidarity activists', 'She', 'Russian television', 'John Kerry', 'law enforcement agencies', 'Aidar fighters', 'Abu Kamal', 'campaign chief', 'Hillary', 'car bombing', 'the people', 'meat', 'around Manbij city east of Aleppo province', 'Syria , Iraq and elsewhere', 'Kerry', '200 unauthorized Polish laborers', 'Ottoman Empire', 'Vladimir Putin and Donald Trump', 'money', 'political opponent', 'protection', 'coalition', 'duopoly', 'losers', 'Maria Haley', 'materials', 'public', 'history', 'them', 'Japanese aircraft carriers', 'Chicago police', 'Dagestan province', 'PYD', 'Boris', 'address in 2000', 'torture technique', 'United Nations', 'Scharipow', 'Colin Powell', 'broad parties', 'money and anti - tank missiles', 'the besieged city', 'Syria and Iraq', 'Hadhramaut', 'youth', 'Rio', 'European Union , the United States , Canada , Australia and Norway', 'We', 'German Chancellor Angela Merkel , French President Francois Hollande , and U.S. President Barack Obama', 'agencies', 'Blackmun', 'the streets', 'illegal reentry', 'homes and positions', 'teenage', 'The growing rift with the West', 'women', 'State Department', 'UBS', 'mishandled classified information', 'Laotian President Bounnhang Vorachit and President Barack Obama', 'cutting agents such as detergents', 'model democracy', 'US products', 'nuclear holocaust', 'Saddam Hussein', \"South Sudan 's leaders\", 'migrant', 'one of the militants', 'Mr. Rubio', 'an academic', 'Latin America', 'Max Boot', 'Qatar and Saudi Arabia', 'Canada', 'Syrian government forces , backed by Russian', 'Gulf states', 'the living area', 'I', '49 people', 'The United States', 'social problems', 'FBI', 'middle class', 'Sarajevo', 'his campaign', 'Putin', 'The coach', 'Nigerian - born doctor Bennet Omalu', 'prominent intellectuals', 'Armenian', 'coalition aircraft', 'Iran', 'Scandinavians', 'Moroccan pilot', 'God', 'Panamanian', 'agents', 'tough - on - crime \" laws', 'attacks', 'plane', 'Seven Christian homes', 'neighbors', 'a society', 'The American state', 'ISIS', 'creation of a caliphate stretching across Syria and Iraq', 'Syria', 'refugees', 'he', 'Granoff', 'all', 'presidential debate', 'panicked fans', 'the police state', 'Prime Minister Nouri al - Maliki', 'Russian war planes', 'Egypt', 'ambush', 'email', 'beating', 'Ukraine and southern Russia', 'Muslim mob', 'Guantanamo bay', 'Hillary Clinton', 'coup', 'group', 'hundreds of thousands of people', 'his group and others', 'former KGB officer', 'hundreds of protesters', 'LA', 'Lynx or bisons or three - toed woodpeckers', 'AQI', 'the Arctic Yamal Peninsula', 'RND', 'aliens', 'VanBuskirk', 'the President', 'dairy and cheese', 'court of last resort', 'goods', 'two countries', 'starve', 'activists from neo - Nazi group Daugavas Vanagi', 'Klong Prem high - security prison', 'Sergey V. Lavrov', 'country', 'Ascenta', 'put American workers first', 'would - be terrorists', 'charity', 'Europe and the United States', 'Nigel Farage', 'swimmers', 'Poland', '1.5 million people', 'supporters', '196 nations', 'Azerbaijani troops', 'Saddam', 'enemies', 'Lord Coe', 'business', 'Wada', 'several films', 'Mike Pence', 'Yamal', 'amnesty', 'planes', 'children and kids', 'Darfur region', 'the point in his final foreign policy', 'George Soros’', 'a gay nightclub in Orlando , Fla.', 'Albania , Montenegro , Iceland and Liechtenstein', \"Saidov 's attacker\", 'appointment', 'members', 'you or your wife or girlfriend', 'milk', 'students', 'Kenya ’s government', 'Centre', 'its sun - mottled interior', 'center - left and leftist governments', 'San Bernardino and Orlando', 'Hispanic voters', 'Bashar al - Assad', 'Ripley and his team', 'Project Veritas videos', 'the convention', 'Facebook', 'the government', 'X6 SUV', 'financial assets', \"suspend Russia 's athletics team\", 'firearms', 'Powell', 'the media', 'sick and wounded', 'prejudicing investigations', 'Russian - funded news network', 'Limbazi', 'Snowden', 'Americans', 'Pyongyang', 'lying', 'international environment', 'Kiev', 'the Kremlin', 'Kurdish YPG militia', 'NSA', 'her and another Benghazi family', 'state council for nature conservation', 'Turkey', 'debate', 'Devin Stewart', 'Yemen', 'us', 'nuclear arsenals', '2009 G20 summit', 'Confederate', 'his cronies', 'relations', 'the United States', 'self - professed Islamic State jihadi Omar Mir Seddique Mateen', 'Plaintiffs', 'Bannon', 'she and French President Francois Hollande', 'foundation', 'bank note validation technology', 'Cleveland', 'Israel', 'a number of areas', 'Muslim soldier', 'poison', 'systems in the U.S.', '$ 20,000', 'bomb', 'man - portable systems', 'his view', 'sucicde bomber', '98 percent of Essar Oil', 'His employees', 'Yanukovych', 'Harry S. Truman', 'Bely Island', 'Civil wars', 'Muslims in Russia', 'Alexandria , Virginia', 'voters', 'free speech', 'activists', 'NATO allies', 'the political world', 'administration', 'McCombs', 'their state', 'Turkish foods', 'hack', '$ 42,000', 'the Muslim world', 'Polish laborers', 'Russian territory', 'opponents', 'Ukraine president and pro - Russia ally , Viktor Yanukovych', 'U.S. authorities', 'Syrians', 'ISIS and Kurdish militants', 'his home state', 'EU', 'Radio Free Europe / Radio Liberty', 'self - radicalized terrorists', 'kiosk', 'Manafort', 'the property', 'UK', 'donors', 'base of the tomb', 'Schiff', 'apostates', 'Falkenberg', 'Iron Dome systems', 'Russia Council', 'Constitutional law', 'the federal government', 'it and the International Olympic Committee', 'Helen Mirren', 'world', 'Mr. Putin', 'food', 'South Africa', 'Senator Robert Taft', 'warriors', 'Polish patrol boat', 'Sergeant Brandon Mendoza', 'Pope', 'Countries', 'New Jersey', 'military aircraft', 'corruption', 'Doral , Florida', 'Clintons', '100 prominent physicians , bioethicists and scientists', 'east side of the Euphrates', 'a Latvian town', 'AIPAC', 'YPG fighters', 'city on the Volga River ( present - day Volgograd )', 'immigrants', 'a group led by Rosneft', 'hundreds of thousands of Filipinos', 'aircraft', 'Australia', 'waterboarding , another method of torture called “ zipping ” in which people are tied to a bed that is then thrown into the air , sexual assault and exploitation , and child abuse', 'a guy from Florida', 'illegal immigrants and other non - citizens', 'Białowieża forest', 'Intelligence officials', 'moderator', 'internet trolls', 'abroad', 'France ’s highest court', 'Right to Rise', 'cyber weapons', 'she', 'Carly Fiorina', 'leader', '$ 100k', 'me', 'The shield', 'Rousseff', 'IS militants', 'Turks', 'World Health Organisation ( WHO )', 'higher global temperatures', 'Honduras', 'place of employment', 'Yahoo', 'our country', 'key players in Washington ’s foreign policy and military establishment', 'Department of Labor', 'Republicans', 'west', 'Rep. Mark Sanford', 'national security interests', 'Ukraine', 'Magliocchetti', 'Bryant', 'south Yemen', 'air strike', 'cars', 'John Quincy Adams', 'Epstein', 'Kurdish and Syrian rebel groups', 'Greece and North Africa', 'divestment and sanctions ( BDS ) movement', 'Bulgarian officials', 'hundreds of wounded', 'Hezbollah', 'state election officials', 'wealthy individuals', 'the American public', 'Thailand', \"EU 's leaders\", 'sick', 'rape', 'Juanita Broaddrick', 'independent group', 'local control in education Press', 'everyone', 'stage', 'explosives', 'interview', 'Brazil', 'Democratic Nominee for Vice President Tim Kaine', 'IS', 'bombing', 'Justice Department', 'Washington', 'Alabama', 'various countries', 'Ecuador', 'its people', 'embargo', 'Maidan', 'more than 1 million people', 'those', 'South Sudan', 'nuclear device', 'them and to their children', 'drug', 'asylum seekers', 'air forces', 'Clinton - Kaine sign', 'superpredators', 'permanent end to the shelling', 'woman', 'Mexico', 'Secretary of State John Kerry', 'here', 'Makani Power', 'Tahir Javed', 'air defense system', 'Iskitim', 'tenant ’s pet', 'a progressive agenda', 'Armenian soldier', \"I 'm\", 'the country', 'city - states', 'clients', 'human liberty', 'The monument to fallen Soviet sailors', 'US', 'Iraq and Syria', 'it', 'tide borrowers', 'liberal critics', 'customs officials', 'the Assad government', 'drug traffickers , smugglers , pirates , kidnappers , jihadists , criminal gangs and militias', 'big money donors', 'Google X', 'her', 'the foreign government', 'Kyrgyzstan', 'Russian families', 'Mosul', 'forest and tundra', 'Soviet Union', 'Mr Powell', 'the two Gulf states', 'Nigeria', 'Laos', 'humankind', 'The director of the European Centre , Ina Kirsch', 'Schmidt', 'Bangkok', 'border', 'Jason D. Meister', 'legislation', \"Russia 's President Vladimir Putin\", 'Barack Obama', 'victim', 'arms', 'It', 'IAAF', 'US military', 'the UK', 'Buk missile', 'council', 'black people', 'violated government policy', 'Mateen', 'Baltic fleet', 'the Shadow Brokers', 'the eastern part of the city', 'U.S. government', 'Russia recover and release Hillary Clinton ’s private emails', 'Assange', 'three to four of his countrymen', 'hysteria', 'fighting', 'Hiroshima and Nagasaki', 'Lev Winogradsky', 'al - Qaeda', 'Florida', 'World Health Organization Director - General Margaret Chan', 'tax vehicle', 'a country', 'Cuba', 'Avenida das Americas', 'copying', 'New York City', 'the city', 'US Rowing', 'Many people working on Syria', 'Talish', 'friends and colleagues', 'dozens of armed groups', 'anyone', 'Wi - Fi', 'Aleppo – the last major rebel stronghold', 'USA Rowing women ’s team', 'deputy', 'surgery', 'region', 'Pacific', 'city', 'Palestinian terrorist', 'the suspended president', 'DCCC', 'foreign leaders', 'one and a half million Armenian people', 'John Quincy', 'Iowa', 'men', 'an alleged Russian intelligence agent', 'Latvian town', 'Wikileaks founder', 'directing the artillery fire', 'NATO', 'assault rifle', 'Silicon Valley', 'helped the US', 'George VanBuskirk', 'the area', 'President Hassan Rouhani', 'Japan', 'following of Donald Trump', 'Trump - Russia special counsel', 'bury', 'US and the UK', 'Middle East', 'anti - free - speech laws', 'rallies', 'military officials', 'five innocent children', 'oil', 'Assad government', 'a car', 'the BDS movement', 'Verizon', 'Iranians', 'boy', 'Bounnhang Vorachit', 'Tartus', 'firebombed', 'reticence', \"Hillary Clinton 's campaign\", 'FBI officials', 'Belarus', 'Darayya', 'U.S government', 'Bitcoin', 'Naryshkin', 'glory', 'IOC members', 'fiscal laws', 'Hillary Clinton ’s email access', 'signs', 'Sweden', 'UN', 'shelling', 'Jeffrey Epstein', 'a Lockheed C-5 Galaxie', 'Omar Bashir', 'him', 'Syrian regime', 'Police officer Timothy Loehmann', 'the Russian army', 'tormentors', 'people', 'high - profile insiders', 'Mark Weiner', 'two hospitals', 'Glen Caplin', 'Manhattan', 'Vietnam', 'assets', 'terrorism', 'the Gulf states', 'protesters', 'Valio dairy company', 'customers', 'Russia ’s prosecutor general', 'Syrian hackers', 'Russian internet trolls', 'Trump or Clinton or Gary Johnson or Jill Stein', 'man - portable missiles', 'UN Security Council', 'guys', 'CIA pilots', 'Jones', 'their [ subscribers ] , donors , budgets , polling , call centres and direct mail campaigns', 'indictments', 'Warm Springs , Georgia', 'cargo', 'doors', 'computer network', 'Homs province', 'three attackers', 'strike area', 'a blast', 'multi - state', 'Russian people', 'U.S. Secretary of State John Kerry and Russian Foreign Minister Sergei Lavrov', 'status as a war hero', 'President of South Korea', 'church', 'the plot', 'his', 'the region', 'spear', 'a man ’s anus', 'car', 'an army of government shills and trolls', '37,000', 'Congress', 'the Ministry of Internal Affairs', 'gang', 'full effects', 'DHS chief', 'cyber - spying tools', 'U.S.', \"uprising and Crimea 's voluntary crossover\", 'boycott supporters', 'Obama administration', '9,000 feet', 'Secretary General Ban Ki - moon', 'Iranian', 'Palestinians', 'Orlando', 'their homes and land', 'a safe distance', 'debt', 'POW camp', 'France , the UK , Germany , and the rest of the West', 'mass', 'Iraq , Libya , and Syria', 'global system—“To', 'the Senate committee responsible for intelligence oversight', 'Republican', 'central Syria', 'leverage', 'models', 'its citizens', 'financial firm', 'patient', 'Justin Trudeau', 'material and other resources', 'strikers', 'Americans ’ call records', 'his government', 'Franco Modigliani', 'Becky', 'three U.S.-Israeli missile defense programs', 'corporate greed', 'Trump campaign', 'President Erdogan', 'buyers', 'bases', 'ground troops', 'appeals not to buy Israeli goods', 'the candidate', 'an Army captain', 'WI', 'Russian generals', 'the past', 'water , food and medical', 'cyber incident', 'TV', 'corporations', 'Istanbul and Ankara', 'Amiri', 'Isik', 'Goldman Sachs', 'two state election websites', 'broadcaster', 'a woman', 'hospital', 'civilian areas in places like Aleppo', 'Mafia members', 'microfinance industry', 'Bank Hapoalim', 'news conference', 'two brave American doctors', 'Palestinian', 'shot', 'a civilian target', 'Mesa', 'Trump events', 'highest bidder', 'families of terrorists', 'assault rifles', 'U.S. troops', 'Joe Biden', 'German troops', 'email hacking', 'power', 'intolerance', 'Putin and Trump', 'mothership', 'banks', 'German prisoners', 'mass killings', 'Mrs. Clinton ’s tenure as Secretary of State', 'terrorism suspects', 'world ’s population', 'Midtown Manhattan', 'leaders of North Korea', 'Head transplantation', 'Air Force', '$ 20', 'hammer and BleachBit software', 'Russians', 'the Presidential Palace in Vientiane , Laos', 'wolves and lynx', 'a television talk show', 'a territory', 'places including Brussels', 'meeting', 'Libya', 'Daraya', 'Palestine', 'Romney lost', 'trailer court', '$ 85 billion', 'head of US intelligence', \"Iran 's Foreign Ministry\", 'eastern Aleppo', 'bottles , chairs and other objects', 'WI 4-H Fdn', 'an honor guard', 'Palmer', '$ 319.9 million', 'boycott', 'citizens', 'Machar', 'civil defense', 'North Little Rock , Arkansas', 'residents', 'the Palestine solidarity movement', 'Medicare', 'London', 'Sea Change Foundation', 'Janet Yellen', 'Democrats , and to Clinton', 'territory', 'people of color', 'ISIL leader', 'Mideast and elsewhere', 'Paris', 'Kasich', 'UAE', 'in', 'Viktor Zolotov', 'town', 'Arab men', \"They 'll\", 'Iron Dome', 'China', 'a hotel', 'the neighbourhood', 'air strikes', 'family', 'American Action Forum', 'movement', 'The men', '$ 75', 'orphanage', 'domain names', 'council member from Russia', 'the film', 'Russian intelligence agencies', 'every commander', 'Istanbul airport', 'McCain', 'strikes', 'homicide', 'Shi’ite protesters', 'tactics more commonly associated with thugs than governments', 'Shahran Amiri', 'the U.S.', 'the nation', 'hackers', 'Border Patrol', 'Geneva', 'Ataturk airport', 'US - led coalition', 'Democratic Party', 'Mexicans', 'a facility in the UK', 'Guccifer', 'Army', 'Israeli goods', 'Wall Street', '$ 24', 'Demilitarized Zone', '4-H Fdn', 'explosion', 'president', 'one another', 'the administration', 'India', 'Team USA triathletes', 'Donald Trump campaign sign', 'American and French soldiers', 'state ’s 72 counties', 'submarine', 'an atomic bomb', 'Washington , DC', 'impeachment proceedings', 'AQAP', 'Mr. Bush', '$ 100 million', '115', 'employees', 'Sayyida Zeinab', 'American public', 'over the Syrian border', 'fraudsters', 'solid support system', 'congressional committee', 'the state ’s 1,854 municipal clerks', 'Vladimir Putin and Russia', 'Roldugin', 'A Chinese official', 'rhetorical concoctions', 'a transgressing politician or two', 'One victim', '9/11 memorial ceremony', 'U.S', 'cities and states', 'her home', 'on stage', 'Mr. Blair', 'Islamic Republic', 'the Palestine solidarity', 'European Union', \"Three members of Mueller 's team\", 'The State Department', 'U.S. 9th Army', 'the current presentation', 'US Navy', 'civilians or fighters', 'Balloon operators', 'charity organization', 'Klong Prem', 'memo', 'Smyrna', 'Kim Jong - un', 'debates', '$ 85 billion in Treasury bonds', 'Marco Rubio', 'experts', 'a senator from Wisconsin', 'Aleppo , Syria', 'sickness', 'the Middle East peace quartet – the US , Russia , the EU and the UN', 'Blais and her roommates', 'Portugal', 'delegates', 'company', 'candidacy', 'Sulaimon Saidov', 'true nature of agreements', 'streets', 'Otto Warmbier', 'staff', 'Rhode Island', 'West', 'GOP opponent', 'false flag \" operations', 'Andover', 'Azerbaijani special forces', 'a building', 'Peter Thiel', 'Tajikistan', 'Mr Wang', 'vote', 'Chechnya', 'the beach', 'criminals', 'rowers', 'criminal wrongdoing', 'technology', 'pay - for - play campaign finance scheme', 'sermons in which he criticized the government', 'THE SENATE', 'the State Department', 'espionage', 'spray painted', 'Nimr al - Nimr , a revered Shi’ite cleric', 'Comey', 'Pence', 'commodities trader', 'ABC', 'attack', 'assault weapons', 'Britain and France', 'Valio', 'Fans', 'U.S. Olympic athletes', 'three countries', 'Soviet', 'Russian Sukhoi Su-24 m bomber', 'Friedrichsfeld', 'those in the country illegally', 'the Senate', 'laws', 'department store', 'He', 'Elie Wiesel', '46 people', 'north Yemen governorate of Saada', 'the pogroms in Ukraine', 'wildfires', 'Richard Holbrooke', 'migrants', 'financial institutions', 'Wikileaks', 'cyberintrusions', 'Apple', 'workers', \"People 's Liberation Army\", 'designer clothing', 'The proceeds', 'Russian and Syrian aircraft', 'civilians', 'USA', 'hundreds of millions of dollars', 'civilian', 'perpetrator', 'terror cases', 'Manafort joined VanBuskirk and others', 'Russian', 'Cohen', 'U.S. Navy', 'The Emergency Ministry', 'United States and France', 'Abedin', 'gays', 'poisoning', '40 percent', 'shooting', 'a man', 'Nagasaki', 'Israeli - American Jew', 'sources', 'two agents', 'team', 'bombs', 'member states', 'Siberian pristine Boreal forests', 'Holbrooke Forum', 'Lee Iacocca', 'detention centres', 'chemical weapons', 'apology could “ open a can of worms on many , many issues', 'GOP presidential nominee Donald Trump', 'Hawaii', 'new federation', 'Russian meddling', 'individual', 'airbase', 'terrorist group', 'the agency ’s humanitarian wing', 'the Court of Cassation', 'cheese', 'Trump ’s agency', 'highly coordinated campaigns', 'suspected hack', 'machines', 'profits', 'Soros', 'Normandy', 'Donald Trump', 'Roosevelt', 'Clinton', 'Bataclan concert hall', 'a fair price', 'the release of any emails from state department servers', 'Brussels', '28 civilians', 'jobs', 'Hofstra University', 'Aleppo', 'genocide', 'besieged areas', 'the average family watching tonight', 'Black Sea', 'trade', 'entry - level floor sweepers', 'armored ground vehicles , ground attack munitions , light air support aircraft ” and “ maritime patrol ships and aircraft', 'data', 'the Muslim - dominated North Caucasus region', 'people in need of medical attention', 'Muslim', 'Israeli', 'embassy in London', 'United States', 'NFL', 'London hotel', 'American', \"Russia 's national athletics federation have been suspended from competition\", 'girl', 'Weiner', 'car bomb and then blown up explosive belts', 'Assad', '237,000', '$ 500 to $ 1,700', '$ 11 million', 'Senate floor', 'boycotts', 'schools', '20 methamphetamine pills', '20,000', 'A new poll', 'CNAS', 'Ecuadorian Embassy', 'South Korea', 'People', 'candidate', 'O’Keefe and his Project Veritas deployed journalists', 'regime', 'the weather', 'International Telecommunication Union', 'Creamer , as well as Foval', 'his family , advisers and allies', 'homes', 'Omaha Beach', 'think tank', 'mobile devices', 'WikiLeaks', 'hanged', 'Los Angeles', 'Yahoo News', 'helmet', 'Vladivostok', 'soldiers and officers', 'U.S. Navy base on Midway Atoll', 'hundreds of items from the very private collection of Ronald Reagan', 'Tiananmen Square', 'a practice', 'Yuri Nagornykh', 'Japanese city', 'illness', 'Paiboon', 'Nagorno - Karabakh', 'information', 'human', 'allowing the killing to continue', '$ 12.7 million', 'Fethullah Gülen Terrorist Organization', 'police', 'New Zealand', 'Caroline Lind', 'U.S. Secretary of State Hillary Clinton', 'government', 'Soviet soldiers', 'airstrikes', 'seat', 'Burkina Faso', 'Russian submarine Krasnodar', 'Organizations', 'starvation', 'director', 'weapons', 'secretary of state', 'overseas', 'Debbie Wasserman Schultz', 'our streets', 'villagers', 'the desert', 'two Gulf states', 'Iraq', 'Muslims', 'Republican nominee Donald Trump', 'revolver', 'ICC', 'social change', 'monument', 'her small wooden shack', '$ 20,000 to $ 40,000', 'watch', 'gunman', 'Iraqi', 'every available military , economic , ideological , diplomatic , cyber and religious lever', 'Japanese', 'the North', 'Azerbaijan and Armenia', 'U.S. banks', 'racial abuse', 'wives and mistresses', 'robbery or assault', '20,000 to $ 40,000', 'French port city of Marseille', 'Islamic State group', 'rebels', 'the Trump Tower', 'overthrow him and introduce reform', 'cocaine', 'treason', 'Sunni tribal leaders', 'A neo - Nazi group , including former Latvian Nazi Waffen SS veterans', 'CNAS paper', 'fears over Syria and economic concerns', 'traveling supporters', '“ legitimate ” freedom of expression online', 'Teotihuacán', 'CIA', 'German soldiers', 'those who pose a threat in cyberspace', 'Ukraine and Russia', 'digital privacy advocacy groups', 'warships', 'Mr. Trump', 'Venezuela', 'they', 'six million victims', 'Britain', 'who', 'Hiroshima', '6,267 inmates', 'D.C.', 'about 20 of those who planned the overnight coup', 'bombing campaigns', 'our', 'intolerance and taking away individuals ’ right to use bathrooms consistent with their gender identity', 'the Korean peninsula', 'Russia', '380 foreign born individuals', 'He and his allies', 'Khans', 'Damascus', 'democratically elected president', 'Islamic State and other militant groups', 'not taking responsibility and of concealing the true nature of agreements they had struck', 'Mr Spiridinov', 'rent', 'Russian banks', 'the two - party system', 'North Korea', 'domestic abusers and those with serious mental health issues', 'drug - related crimes', 'USA triathletes', 'Senate Subcommittee on Immigration', 'Klein', 'the FBI', 'drones and warplanes', 'investigations', 'Reporters', 'More than 100 prominent physicians , bioethicists and scientists from around the world', 'Armenians', '$ 4', 'Iran and China', 'judge', 'embassy', 'former models', 'Myanmar ( Burma ) , Russia , China or Mexico', 'BDS ) movement', 'Islamic State', 'Vadinar', 'Russian and Syrian government', 'Lobbyist', 'monsters', 'Chicago', 'Cruz', 'the practice', 'Mr Roslovtsev', 'Democrats', 'the Hill', 'Oklahoma', 'Rubio', 'Marseille', 'Sanders', '17-year - old Laquan McDonald', 'neo - Nazi group', 'gun', 'Officer Jason Van Dyke', 'mugger', 'Reagan', 'looting', 'child sex abuse', 'the world', 'stadium', 'José Manuel Zelaya', 'a group', 'Fox News Sunday ” interview', 'Christie ’s', 'Lind', 'eastern Ukraine', '\" false flag \" operations', 'methane gas', 'three crucial states', 'parents', 'funding', 'Democratic platform committee', 'Russia and Putin', 'regions', 'Russian media', 'Romania', 'They', 'Tamir Rice', 'prisons', 'factions', 'loved ones', 'Good Morning Britain', 'Ronald Reagan Presidential Foundation and Institute', 'taxes', 'IRS', 'whom', 'White House']\n",
      "(220, 611)\n"
     ]
    }
   ],
   "source": [
    "print(list(H.nodes))\n",
    "removed_nodes = [node for node in H.nodes if H.degree(node) == 1]\n",
    "SH = H.remove_nodes(removed_nodes)\n",
    "print(SH.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_frontend(nodes, links, nodes_dict, hyper_edges_dict):\n",
    "    res_nodes = []\n",
    "    res_links = []\n",
    "    for node in nodes:\n",
    "        if node in nodes_dict:\n",
    "            res_nodes.append(nodes_dict[node])\n",
    "        else:\n",
    "            res_nodes.append(hyper_edges_dict[node])\n",
    "    for link in links:\n",
    "        source = link[0]\n",
    "        target = link[1]\n",
    "        res_links.append({\n",
    "            \"source\": source,\n",
    "            \"target\": target,\n",
    "        })\n",
    "    print(len(res_nodes))\n",
    "    return {\n",
    "        \"nodes\": res_nodes, \n",
    "        \"links\": res_links\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2073\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "BH = H.bipartite()\n",
    "BSH = SH.bipartite()\n",
    "network = transform_frontend(list(BH.nodes), list(BH.edges), nodes_dict, hyper_edges_dict)\n",
    "save_json(network, 'data/result/RAMS/dev_subgraph.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "event_hgraph_preprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
