{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import json\n",
    "import requests\n",
    "import random\n",
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai.api_key = open(\"api_key\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, filepath=r'new_data.json'):\n",
    "    with open(filepath, 'w') as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "def request_chatgpt_gpt4(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        # model=\"text-davinci-003\",\n",
    "        # model=\"gpt-4\",\n",
    "        model=\"gpt-3.5-turbo-16k-0613\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "    url = \"http://127.0.0.1:5000/event_hgraph\"\n",
    "    body = {\"messages\": messages}\n",
    "    response = requests.post(url, json=body).json()\n",
    "    gpt_response = response['choices'][0]['message']['content'].strip()\n",
    "    return gpt_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the prompts to generate topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterLabelToNodes(cluster_labels, partition, hyperedge_dict):\n",
    "    reverse_partition = defaultdict(list)\n",
    "    for node_id, cluster_label in partition.items():\n",
    "        reverse_partition[str(cluster_label)].append(node_id)\n",
    "    hyperedges = []\n",
    "    for cluster_label in cluster_labels:\n",
    "        for hyperedge_id in reverse_partition[cluster_label.split(\"-\")[2]]:\n",
    "            hyperedges.append(hyperedge_dict[hyperedge_id])\n",
    "\n",
    "    return hyperedges\n",
    "\n",
    "def query_leaf_topic(nodes, node_type):\n",
    "    if node_type == 'article':\n",
    "        # example = json.load(open(r'data/result/AllTheNews/cluster_summary/example_article.json'))\n",
    "        example = json.load(open(r'data/result/VisPub/cluster_summary/example_article.json'))\n",
    "        summaries = [node['summary'] for node in nodes]\n",
    "        summaries_message = \"\"\n",
    "        for index, summary in enumerate(summaries):\n",
    "            # summaries_message += \"Article {}: \\n\".format(index+1)\n",
    "            summaries_message += \"Abstract {}: \\n\".format(index+1)\n",
    "            summaries_message += summary + '\\n\\n\\n'\n",
    "        messages = [\n",
    "            # All The News\n",
    "            # { \n",
    "            #     \"role\": \"system\", \n",
    "            #     \"content\": \"\"\"\n",
    "            #         You are a news article summarization system. \n",
    "            #         The user will provide you with a set of summarized news articles, your job is to further summarize them into one noun phrase.\n",
    "            #         Use words that are already in the articles, and try to use as few words as possible.\n",
    "            #     \"\"\"\n",
    "            # },\n",
    "            # VisPub\n",
    "            \n",
    "            { \n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"\n",
    "                    You are a visualization research paper summarization system. \n",
    "                    The user will provide you with a set of abstracts of visualization research papers.\n",
    "                    They are manually categorized by another person, so they are discussing the same topic.\n",
    "                    Your job is to find out what that topic is.\n",
    "                    Reply with less than five words. \n",
    "                \"\"\"\n",
    "            },\n",
    "            { \"role\": \"system\", \"name\": \"example_user\", \"content\": example['leaf']['summaries']},\n",
    "            { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['leaf']['topic']},\n",
    "            { \"role\": \"user\", \"content\": summaries_message}\n",
    "        ]\n",
    "        topic = request_chatgpt_gpt4(messages)\n",
    "        return topic\n",
    "    else:\n",
    "        # example = json.load(open(r'data/result/AllTheNews/cluster_summary/example_entity.json'))\n",
    "        # example = json.load(open(r'data/result/VisPub/cluster_summary/example_entity.json'))\n",
    "        if len(nodes) > 20:\n",
    "            print(\"querying non-leaf\")\n",
    "            messages = [\n",
    "            # All The News\n",
    "            # { \n",
    "            #     \"role\": \"system\", \n",
    "            #     \"content\": \"\"\"\n",
    "            #         You are an entity summarization system.\n",
    "            #         The user will provide you with a list of entities, they can be people, places, or things.\n",
    "            #         The user wants to get a gist of what entities are in the list.\n",
    "            #         First, split the entities into different categories.\n",
    "            #         Then, assign each category a human-readable name.\n",
    "            #         If entities in a category are all related to a specific entity, use that entity as the category.\n",
    "            #         Limit the number of categories to be less than 5 by keeping only the important categories.\n",
    "            #         Reply with the following format:\n",
    "            #         Category 1, Category 2, Category 3, ...\n",
    "            #         Do not reply more than 5 categories.\n",
    "            #     \"\"\"\n",
    "            # },\n",
    "\n",
    "            # VisPub\n",
    "            { \n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"\n",
    "                    You are an visualization research paper keyword summarization system.\n",
    "                    The user will provide you with a list of keywords, they are terminologies in visualization research papers.\n",
    "                    The user wants to get a gist of what keywords are in the list, but the list is too long.\n",
    "                    First, split the keywords into different categories.\n",
    "                    Then, assign each category a human-readable name.\n",
    "                    If keywords in a category are all related to a specific keyword, use that keyword as the category.\n",
    "                    Limit the number of categories to be less than 5 by keeping only the important categories.\n",
    "                    Do not reply more than 5 categories.\n",
    "                    Reply with the following format in a single line:\n",
    "                    Category_1, Category_2, Category_3, ...\n",
    "                \"\"\"\n",
    "            },\n",
    "            # # # example 0\n",
    "            # { \"role\": \"system\", \"name\": \"example_user\", \"content\": \n",
    "            # \"\"\"\n",
    "            # Entities: {} \\n\n",
    "            # \"\"\".format(example['non-leaf'][0]['entities'])\n",
    "            # },\n",
    "            # { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['non-leaf'][0]['category']},\n",
    "            # # example 1\n",
    "            # { \"role\": \"system\", \"name\": \"example_user\", \"content\": \n",
    "            # \"\"\"\n",
    "            # Entities: {} \\n\n",
    "            # \"\"\".format(example['non-leaf'][1]['entities'])\n",
    "            # },\n",
    "            # { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['non-leaf'][1]['category']},\n",
    "            { \"role\": \"user\", \"content\": \n",
    "            \"\"\"\n",
    "            Keywords: {} \\n\n",
    "            \"\"\".format(\", \".join(nodes))\n",
    "            }\n",
    "        ]\n",
    "        else:        \n",
    "            print(\"querying leaf\")\n",
    "            messages = [\n",
    "                # All The News\n",
    "                # { \n",
    "                #     \"role\": \"system\", \n",
    "                #     \"content\": \"\"\"\n",
    "                #         You are an entity summarization system.\n",
    "                #         The user will provide you with a list of entities, they can be people, places, or things.\n",
    "                #         The user wants to get a gist of what entities are in the list.\n",
    "                #         Pick out a few entities that best represents the list.\n",
    "                #         Avoid picking out overlapping entities.\n",
    "                #         Limit the number of picked entities to be less than 5 by keeping only the important ones.\n",
    "                #     \"\"\"\n",
    "                # },\n",
    "\n",
    "                { \n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"\"\"\n",
    "                        You are an visualization research paper keyword summarization system.\n",
    "                        The user will provide you with a list of keywords, they are terminologies in visualization research papers.\n",
    "                        The user wants to get a gist of what keywords are in the list, but the list is too long.\n",
    "                        Pick out only a few keywords that best represents the list.\n",
    "                        Avoid picking out overlapping keywords.\n",
    "                        Limit the number of picked keywords to be less than 5 by keeping only the important ones.\n",
    "                        Reply with the following format:\n",
    "                        Keyword_1, Keyword_2, Keyword_3, ...\n",
    "                    \"\"\"\n",
    "                },\n",
    "                # # example 1\n",
    "                # { \"role\": \"system\", \"name\": \"example_user\", \"content\": \n",
    "                # \"\"\"\n",
    "                # Entities: {} \\n\n",
    "                # What kinds of entities are there? \\n\n",
    "                # \"\"\".format(example['leaf'][0]['entities'])\n",
    "                # },\n",
    "                # { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['leaf'][0]['category']},\n",
    "                # # example 2\n",
    "                # { \"role\": \"system\", \"name\": \"example_user\", \"content\": \n",
    "                # \"\"\"\n",
    "                # Entities: {} \\n\n",
    "                # What kinds of entities are there? \\n\n",
    "                # \"\"\".format(example['leaf'][1]['entities'])\n",
    "                # },\n",
    "                # { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['leaf'][1]['category']},\n",
    "                # user input\n",
    "                { \"role\": \"user\", \"content\": \n",
    "                \"\"\"\n",
    "                Keywords: {} \\n\n",
    "                \"\"\".format(\", \".join(nodes))\n",
    "                }\n",
    "            ]\n",
    "        topic = request_chatgpt_gpt4(messages)\n",
    "        return topic\n",
    "\n",
    "def query_cluster_topic(cluster_subtopics, cluster_samples, node_type):\n",
    "    if node_type == 'article':\n",
    "        # example = json.load(open(r'data/result/AllTheNews/cluster_summary/example_article.json'))\n",
    "        example = json.load(open(r'data/result/VisPub/cluster_summary/example_article.json'))\n",
    "        query = \"Sub-topics: \"\n",
    "        sample_summaries = \"\"\n",
    "        query += \", \".join(cluster_subtopics) + '\\n\\n\\n'\n",
    "        for index, cluster_sample in enumerate(cluster_samples):\n",
    "            # sample_summaries += \"Article {}: \\n\".format(index+1)\n",
    "            sample_summaries += \"Abstract {}: \\n\".format(index+1)\n",
    "            sample_summaries += cluster_sample['summary'] + '\\n\\n\\n'\n",
    "\n",
    "        # All The News\n",
    "        # messages = [\n",
    "        #     { \n",
    "        #         \"role\": \"system\", \n",
    "        #         \"content\": \"\"\"\n",
    "        #             You are a news article categorization system. \n",
    "        #             The user will provide you with a list of sub-topics of news articles and a few examples from the sub-topics.\n",
    "        #             Your job is to further categorize the sub-topics into a single noun-phrase that best summarizes all the sub-topics.\n",
    "        #             Try to reuse the words in the examples.\n",
    "        #         \"\"\"\n",
    "        #     },\n",
    "        #     { \"role\": \"system\", \"name\": \"example_user\", \"content\": example['non-leaf']['summaries']},\n",
    "        #     { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['non-leaf']['topic']},\n",
    "        #     { \"role\": \"user\", \"content\": query}\n",
    "        # ]\n",
    "\n",
    "        # VisPub\n",
    "        messages = [\n",
    "            { \n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"\n",
    "                    You are a visualization research paper summarization system. \n",
    "                    You generate topics for a set of visualization research papers.\n",
    "                    The user will provide you with a list of sub-topics and a few example abstracts from the sub-topics.\n",
    "                    Your job is to further categorize the sub-topics into a single noun-phrase that best summarizes all the sub-topics.\n",
    "                    Try to reuse the words in the sub-topics.\n",
    "                    Reply with a single noun phrase without any line breaks. \n",
    "                    Be as concise as possible.\n",
    "                \"\"\"\n",
    "            },\n",
    "            { \"role\": \"system\", \"name\": \"example_user\", \"content\": example['non-leaf']['summaries']},\n",
    "            { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['non-leaf']['topic']},\n",
    "            { \"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        topic = request_chatgpt_gpt4(messages)\n",
    "        return topic\n",
    "    else:\n",
    "        return\n",
    "\n",
    "def add_hierarchical_topic(hierarchy, partitions, hyperedge_dict, topic_dict, filepath, sampleFlag=True):\n",
    "    dfs(hierarchy, partitions, hyperedge_dict, topic_dict, filepath, sampleFlag)\n",
    "    return topic_dict\n",
    "\n",
    "def dfs(hierarchy, partitions, hyperedge_dict, topic_dict, filepath, sampleFlag=True):\n",
    "    level = int(hierarchy['key'].split('-')[1])\n",
    "    if level == 1: # at level 1, use the children (leaf nodes) to generate a topic\n",
    "        # collect the leaf node summaries\n",
    "        children_labels = list(map(lambda x: x['key'], hierarchy['children']))\n",
    "        # articles = clusterLabelToNodes(children_labels, partitions[0], hyperedge_dict)\n",
    "        entities = clusterLabelToNodes(children_labels, partitions[0], hyperedge_dict)\n",
    "        # entity\n",
    "        entity_titles = [entity['title'] for entity in entities]\n",
    "        if hierarchy['key'] in topic_dict: return # if already have a topic, skip. This happens when continuing from a break point\n",
    "\n",
    "        # generate the topic\n",
    "        # gpt_topic = query_leaf_topic(entity_titles, node_type='entity')\n",
    "        print(entity_titles)\n",
    "        gpt_topic = query_leaf_topic(entity_titles, node_type='entity')\n",
    "        # record the result\n",
    "        topic_dict[hierarchy['key']] = gpt_topic\n",
    "        save_json(topic_dict, filepath)\n",
    "        print(hierarchy['key'], gpt_topic)\n",
    "        return\n",
    "    else:\n",
    "        sub_topic_samples = [] # samples from the sub-topics\n",
    "        all_articles = []\n",
    "        # standard dfs\n",
    "        for child in hierarchy['children']:\n",
    "            dfs(child, partitions, hyperedge_dict, topic_dict, filepath, sampleFlag)\n",
    "            # sample from the sub-topics\n",
    "            level = int(child['key'].split('-')[1])\n",
    "            # articles = clusterLabelToNodes([child['key']], partitions[level], hyperedge_dict)\n",
    "            entities = clusterLabelToNodes([child['key']], partitions[level], hyperedge_dict)\n",
    "            # if sampleFlag:\n",
    "            #     sample = articles[0]\n",
    "            #     sub_topic_samples.append(sample)\n",
    "            # all_articles += articles\n",
    "        if hierarchy['key'] in topic_dict: return # if already have a topic, skip. This happens when continuing from a break point\n",
    "        # use the sub-topics and samples to generate a topic for the current node\n",
    "        # article\n",
    "        cluster_subtopics = [topic_dict[child['key']] for child in hierarchy['children']]\n",
    "\n",
    "        # entity\n",
    "        # cluster_subtopics = [topic_dict[child['key']].split(\",\") for child in hierarchy['children']]\n",
    "        # cluster_subtopics = [item.strip() for sublist in cluster_subtopics for item in sublist] # flatten\n",
    "        if sampleFlag:\n",
    "            sample_articles = random.sample(all_articles, min(10, len(all_articles)))\n",
    "        # generate the topic\n",
    "        # article\n",
    "        # gpt_topic = query_cluster_topic(cluster_subtopics, sample_articles, node_type='entity')\n",
    "        # entity\n",
    "        # print(\"non-leaf: \", cluster_subtopics)\n",
    "        gpt_topic = query_leaf_topic(cluster_subtopics, node_type='entity')\n",
    "        # record the result\n",
    "        topic_dict[hierarchy['key']] = gpt_topic\n",
    "        save_json(topic_dict, filepath)\n",
    "        print(hierarchy['key'], gpt_topic)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is where the main function begins\n",
    "### I've helped you change the variable names (from hyperedges to entities) and kept the original line. \n",
    "### You should know that when I wrote the code, hyperedges == articles.\n",
    "### In your context, you will operate on entities instead.\n",
    "### This is just for your reference when you want to understand the testing/debugging codes\n",
    "### Be aware that in the dfs functions, variables of 'hyperedges' is not renamed to 'entities'. \n",
    "### Rename them if you feel confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read in hierarchy and partition\n",
    "# entity\n",
    "# hierarchy = json.load(open('data/result/AllTheNews/network/server/ravasz_hierarchies_entity.json'))\n",
    "# partitions = json.load(open('data/result/AllTheNews/network/server/ravasz_partitions_entity.json'))\n",
    "hierarchy = json.load(open('data/result/VisPub/network/server/ravasz_hierarchies_entity.json'))\n",
    "partitions = json.load(open('data/result/VisPub/network/server/ravasz_partitions_entity.json'))\n",
    "# article\n",
    "# hierarchy = json.load(open('data/result/AllTheNews/network/server/ravasz_hierarchies_article.json'))\n",
    "# partitions = json.load(open('data/result/AllTheNews/network/server/ravasz_partitions_article.json'))\n",
    "# hierarchy = json.load(open('data/result/VisPub/network/server/ravasz_hierarchies_article.json'))\n",
    "# partitions = json.load(open('data/result/VisPub/network/server/ravasz_partitions_article.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Read in entities. \n",
    "# entities_dict = json.load(open('data/result/AllTheNews/network/entities.json'))\n",
    "entities_dict = json.load(open('data/result/VisPub/network/entities.json'))\n",
    "# hyperedges_dict = json.load(open('data/result/AllTheNews/network/hyperedges.json')) # the original line\n",
    "# articles_dict = json.load(open('data/result/VisPub/network/articles.json')) # the original line\n",
    "\n",
    "# 3. generate topic. hierarchical_topics.json should be empty at first\n",
    "# entity\n",
    "# topic_dict = json.load(open('data/result/AllTheNews/hierarchical_topics_entities_raw.json'))\n",
    "# topic_dict = json.load(open('data/result/VisPub/hierarchical_topics_articles.json'))\n",
    "topic_dict = json.load(open('data/result/VisPub/hierarchical_topics_entities.json'))\n",
    "# breakpoint_filepath = 'data/result/AllTheNews/hierarchical_topics_entities_raw.json'\n",
    "# breakpoint_filepath = 'data/result/VisPub/hierarchical_topics_articles.json'\n",
    "breakpoint_filepath = 'data/result/VisPub/hierarchical_topics_entities.json'\n",
    "\n",
    "# article\n",
    "# topic_dict = json.load(open('data/result/AllTheNews/hierarchical_topics_articles.json'))\n",
    "# topic_dict = add_hierarchical_topic(hierarchy, par, hyperedges_dict, topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sorry', 'unfortunately']\n",
      "querying leaf\n",
      "L-1-1800 Unfortunately\n",
      "['v v']\n",
      "querying leaf\n",
      "L-1-478 v\n"
     ]
    }
   ],
   "source": [
    "# topic_dict = add_hierarchical_topic(hierarchy, partitions, articles_dict, topic_dict, breakpoint_filepath, sampleFlag=True)\n",
    "topic_dict = add_hierarchical_topic(hierarchy, partitions, entities_dict, topic_dict, breakpoint_filepath, sampleFlag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-13 \n",
    "1-934\n",
    "2-208\n",
    "2-207\n",
    "1-1377\n",
    "2-71\n",
    "\n",
    "1-1227\n",
    "2-264\n",
    "1-649\n",
    "1-188\n",
    "\n",
    "1-569\n",
    "2-213\n",
    "3-10\n",
    "1-657\n",
    "2-245\n",
    "3-14\n",
    "1-146\n",
    "1-599\n",
    "\n",
    "1-1469\n",
    "2-249\n",
    "1-795\n",
    "1-1210\n",
    "1-705\n",
    "1-1241\n",
    "1-105\n",
    "1-1189\n",
    "\n",
    "2-82\n",
    "1-64\n",
    "1-262\n",
    "1-91\n",
    "1-1830\n",
    "1-642\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are testing/debugging functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = defaultdict(list)\n",
    "for node_id, cluster_id in partitions[1].items():\n",
    "    clusters[cluster_id].append(node_id)\n",
    "test_cluster = [articles_dict[hyperedge_id] for hyperedge_id in clusters[332]]\n",
    "print(len(test_cluster))\n",
    "for article in test_cluster:\n",
    "    print(article['id'], article['summary'])\n",
    "query_leaf_topic(test_cluster, node_type='article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_cluster = hierarchy['children'][0]['children'][0]['children'][1]['children'][1]\n",
    "target_cluster = hierarchy['children'][0]['children'][0]['children'][0]['children'][3]\n",
    "len(target_cluster['children']), [cluster['key'] for cluster in target_cluster['children']], target_cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_cluster = hierarchy['children'][2]['children'][1]['children'][1]['children'][0]\n",
    "target_cluster = hierarchy['children'][0]['children'][0]['children'][0]['children'][3]\n",
    "topics = json.load(open('data/result/AllTheNews/hierarchical_topics_entities_mod.json'))\n",
    "cluster_children = [child['key'] for child in target_cluster['children']]\n",
    "sub_topic_samples = []\n",
    "# topic_dict = {}\n",
    "# for child in target_cluster['children']:\n",
    "    # # if len(child['children']) > 10 or len(child['children']) < 3: \n",
    "    # #     continue\n",
    "    # level = int(child['key'].split('-')[1])\n",
    "    # entities = clusterLabelToHyperedge([child['key']], partitions[level], entities_dict)\n",
    "    # entity_titles = [entity['title'] for entity in entities]\n",
    "    # print(target_cluster['key'], topics[target_cluster['key']], child['key'], len(entities), len(child['children']))\n",
    "    # print(\", \".join(entity_titles))\n",
    "    # sub_topic = topics[child['key']]\n",
    "    # print(sub_topic, new_sub_topic)\n",
    "    # print(\"----------------------\")\n",
    "    # topic_dict[child['key']] = sub_topic\n",
    "    # sample = hyperedges[0]\n",
    "    # sub_topic_samples.append(sample)\n",
    "cluster_subtopics = [topic_dict[child['key']].split(\",\") for child in target_cluster['children']]\n",
    "cluster_subtopics = [item.strip() for sublist in cluster_subtopics for item in sublist] # flatten\n",
    "new_sub_topic = query_leaf_topic(cluster_subtopics, 'entity')\n",
    "print(target_cluster['key'], topic_dict[target_cluster['key']])\n",
    "print(cluster_subtopics)\n",
    "print(new_sub_topic)\n",
    "print(\"---------------------\")\n",
    "# pprint(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = [613, 332, 880]\n",
    "# cluster_subtopics = [\n",
    "#     'Increasing Gun Violence in Chicago',\n",
    "#     'Crime Rates and Policing Tactics',\n",
    "#     'Misconceptions about Crime in the United States',\n",
    "#     'Global Events and Optimism',\n",
    "# ]\n",
    "sub_cluster_topics = {\n",
    "    \"L-1-613\": \"Underwater 3D scene reconstruction from acoustic imaging sonar data\",\n",
    "    \"L-1-332\": \"Visualization of Sound Propagation in Room Acoustics\",\n",
    "    \"L-1-880\": \"Underwater seabed visualization\",\n",
    "}\n",
    "# cluster_subtopics = [topic_dict[\"L-1-{}\".format(cluster_label)] for cluster_label in children]\n",
    "cluster_samples = []\n",
    "clusters = defaultdict(list)\n",
    "for node_id, cluster_label in partitions[1].items():\n",
    "    clusters[cluster_label].append(node_id)\n",
    "for cluster_label in children:\n",
    "    cluster_samples += clusters[cluster_label]\n",
    "print(cluster_samples)\n",
    "cluster_samples = random.sample(cluster_samples, min(10, len(cluster_samples)))\n",
    "cluster_subtopics = list(sub_cluster_topics.values())\n",
    "cluster_samples = [articles_dict[sample] for sample in cluster_samples]\n",
    "topic = query_cluster_topic(cluster_subtopics, cluster_samples, node_type='article')\n",
    "sample_summaries = [sample['summary'] for sample in cluster_samples]\n",
    "\n",
    "example = \"\"\n",
    "for index, summary in enumerate(sample_summaries):\n",
    "    # print(summary)\n",
    "    example += \"Abstract {}: \\n\".format(index+1)\n",
    "    example += summary + '\\n\\n\\n'\n",
    "# save_json(example, 'example_article.json')\n",
    "# print(example)\n",
    "pprint(cluster_subtopics)\n",
    "print(topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for generating few-show examples for the prompt\n",
    "sample_summaries = \"Sub-topics: \"\n",
    "sample_summaries += \", \".join(cluster_subtopics) + '\\n\\n\\n'\n",
    "for index, cluster_sample in enumerate(cluster_samples):\n",
    "    sample_summaries += \"Article {}: \\n\".format(index+1)\n",
    "    sample_summaries += cluster_sample['summary'] + '\\n\\n\\n'\n",
    "example = json.load(open(r'data/result/AllTheNews/cluster_summary/example.json'))\n",
    "example['non-leaf']['summaries'] = sample_summaries\n",
    "example['non-leaf']['topic'] = 'Crimes in the United States'\n",
    "save_json(example, r'data/result/AllTheNews/cluster_summary/example.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = json.load(open('data/result/AllTheNews/hierarchical_topics_entities_raw.json'))\n",
    "level_1_topics = {}\n",
    "for cluster, topic in topics.items():\n",
    "    level = int(cluster.split(\"-\")[1])\n",
    "    if level < 2:\n",
    "        level_1_topics[cluster] = topic\n",
    "save_json(level_1_topics, 'data/result/AllTheNews/hierarchical_topics_entities_raw.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "event_hgraph_preprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
