{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import json\n",
    "import requests\n",
    "import random\n",
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, filepath=r'new_data.json'):\n",
    "    with open(filepath, 'w') as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "# From Sam: \n",
    "# I believe you have a different query approach. Feel free to switch to yours.\n",
    "def request_chatgpt_gpt4(messages):\n",
    "    url = \"http://127.0.0.1:5000/event_hgraph\"\n",
    "    body = {\"messages\": messages}\n",
    "    response = requests.post(url, json=body).json()\n",
    "    gpt_response = response['choices'][0]['message']['content'].strip()\n",
    "    return gpt_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the prompts to generate topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterLabelToHyperedge(cluster_labels, partition, hyperedge_dict):\n",
    "    reverse_partition = defaultdict(list)\n",
    "    for node_id, cluster_label in partition.items():\n",
    "        reverse_partition[str(cluster_label)].append(node_id)\n",
    "    hyperedges = []\n",
    "    for cluster_label in cluster_labels:\n",
    "        for hyperedge_id in reverse_partition[cluster_label.split(\"-\")[2]]:\n",
    "            hyperedges.append(hyperedge_dict[hyperedge_id])\n",
    "\n",
    "    return hyperedges\n",
    "\n",
    "def query_leaf_topic(nodes, node_type):\n",
    "    if node_type == 'article':\n",
    "        example = json.load(open(r'data/result/AllTheNews/cluster_summary/example_article.json'))\n",
    "        summaries = [node['summary'] for node in nodes]\n",
    "        summaries_message = \"\"\n",
    "        for index, summary in enumerate(summaries):\n",
    "            summaries_message += \"Article {}: \\n\".format(index+1)\n",
    "            summaries_message += summary + '\\n\\n\\n'\n",
    "        messages = [\n",
    "            { \n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"\n",
    "                    You are a news article summarization system. \n",
    "                    The user will provide you with a set of summarized news articles, your job is to further summarize them into one noun phrase.\n",
    "                    Use words that are already in the articles, and try to use as few words as possible.\n",
    "                \"\"\"\n",
    "            },\n",
    "            { \"role\": \"system\", \"name\": \"example_user\", \"content\": example['leaf']['summaries']},\n",
    "            { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['leaf']['topic']},\n",
    "            { \"role\": \"user\", \"content\": summaries_message}\n",
    "        ]\n",
    "        topic = request_chatgpt_gpt4(messages)\n",
    "        return topic\n",
    "    else:\n",
    "        example = json.load(open(r'data/result/AllTheNews/cluster_summary/example_entity.json'))\n",
    "        if len(nodes) > 20:\n",
    "            print(\"querying non-leaf\")\n",
    "            messages = [\n",
    "            { \n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"\n",
    "                    You are an entity summarization system.\n",
    "                    The user will provide you with a list of entities, they can be people, places, or things.\n",
    "                    The user wants to get a gist of what entities are in the list.\n",
    "                    First, split the entities into different categories.\n",
    "                    Then, assign each category a human-readable name.\n",
    "                    If entities in a category are all related to a specific entity, use that entity as the category.\n",
    "                    Limit the number of categories to be less than 5 by keeping only the important categories.\n",
    "                    Reply with the following format:\n",
    "                    Category 1, Category 2, Category 3, ...\n",
    "                    Do not reply more than 5 categories.\n",
    "                \"\"\"\n",
    "            },\n",
    "            # example 0\n",
    "            { \"role\": \"system\", \"name\": \"example_user\", \"content\": \n",
    "            \"\"\"\n",
    "            Entities: {} \\n\n",
    "            \"\"\".format(example['non-leaf'][0]['entities'])\n",
    "            },\n",
    "            { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['non-leaf'][0]['category']},\n",
    "            # example 1\n",
    "            { \"role\": \"system\", \"name\": \"example_user\", \"content\": \n",
    "            \"\"\"\n",
    "            Entities: {} \\n\n",
    "            \"\"\".format(example['non-leaf'][1]['entities'])\n",
    "            },\n",
    "            { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['non-leaf'][1]['category']},\n",
    "            { \"role\": \"user\", \"content\": \n",
    "            \"\"\"\n",
    "            Entities: {} \\n\n",
    "            \"\"\".format(\", \".join(nodes))\n",
    "            }\n",
    "        ]\n",
    "        else:        \n",
    "            messages = [\n",
    "                { \n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"\"\"\n",
    "                        You are an entity summarization system.\n",
    "                        The user will provide you with a list of entities, they can be people, places, or things.\n",
    "                        The user wants to get a gist of what entities are in the list.\n",
    "                        Pick out a few entities that best represents the list.\n",
    "                        Avoid picking out overlapping entities.\n",
    "                        Limit the number of picked entities to be less than 5 by keeping only the important ones.\n",
    "                    \"\"\"\n",
    "                },\n",
    "                # example 1\n",
    "                { \"role\": \"system\", \"name\": \"example_user\", \"content\": \n",
    "                \"\"\"\n",
    "                Entities: {} \\n\n",
    "                What kinds of entities are there? \\n\n",
    "                \"\"\".format(example['leaf'][0]['entities'])\n",
    "                },\n",
    "                { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['leaf'][0]['category']},\n",
    "                # example 2\n",
    "                { \"role\": \"system\", \"name\": \"example_user\", \"content\": \n",
    "                \"\"\"\n",
    "                Entities: {} \\n\n",
    "                What kinds of entities are there? \\n\n",
    "                \"\"\".format(example['leaf'][1]['entities'])\n",
    "                },\n",
    "                { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['leaf'][1]['category']},\n",
    "                # example 3\n",
    "                # { \"role\": \"system\", \"name\": \"example_user\", \"content\": \n",
    "                #  \"\"\"\n",
    "                #  Entities: {} \\n\n",
    "                #  What kinds of entities are there? \\n\n",
    "                #  \"\"\".format(example['leaf'][2]['entities'])\n",
    "                # },\n",
    "                # { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['leaf'][2]['category']},\n",
    "                # user input\n",
    "                { \"role\": \"user\", \"content\": \n",
    "                \"\"\"\n",
    "                Entities: {} \\n\n",
    "                What kinds of entities are there? \\n\n",
    "                \"\"\".format(\", \".join(nodes))\n",
    "                }\n",
    "            ]\n",
    "        topic = request_chatgpt_gpt4(messages)\n",
    "        return topic\n",
    "\n",
    "def query_cluster_topic(cluster_subtopics, cluster_samples, node_type):\n",
    "    if node_type == 'article':\n",
    "        example = json.load(open(r'data/result/AllTheNews/cluster_summary/example.json'))\n",
    "        query = \"Sub-topics: \"\n",
    "        sample_summaries = \"\"\n",
    "        query += \", \".join(cluster_subtopics) + '\\n\\n\\n'\n",
    "        for index, cluster_sample in enumerate(cluster_samples):\n",
    "            sample_summaries += \"Article {}: \\n\".format(index+1)\n",
    "            sample_summaries += cluster_sample['summary'] + '\\n\\n\\n'\n",
    "\n",
    "        messages = [\n",
    "            { \n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"\n",
    "                    You are a news article categorization system. \n",
    "                    The user will provide you with a list of sub-topics of news articles and a few examples from the sub-topics.\n",
    "                    Your job is to further categorize the sub-topics into a single noun-phrase that best summarizes all the sub-topics.\n",
    "                    Try to reuse the words in the examples.\n",
    "                \"\"\"\n",
    "            },\n",
    "            { \"role\": \"system\", \"name\": \"example_user\", \"content\": example['non-leaf']['summaries']},\n",
    "            { \"role\": \"system\", \"name\": \"example_system\", \"content\": example['non-leaf']['topic']},\n",
    "            { \"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        topic = request_chatgpt_gpt4(messages)\n",
    "        return topic\n",
    "    else:\n",
    "        return\n",
    "\n",
    "def add_hierarchical_topic(hierarchy, partitions, hyperedge_dict, topic_dict, filepath, sampleFlag=True):\n",
    "    dfs(hierarchy, partitions, hyperedge_dict, topic_dict, filepath, sampleFlag)\n",
    "    return topic_dict\n",
    "\n",
    "def dfs(hierarchy, partitions, hyperedge_dict, topic_dict, filepath, sampleFlag=True):\n",
    "    level = int(hierarchy['key'].split('-')[1])\n",
    "    if level == 1: # at level 1, use the children (leaf nodes) to generate a topic\n",
    "        # collect the leaf node summaries\n",
    "        children_labels = list(map(lambda x: x['key'], hierarchy['children']))\n",
    "        hyperedges = clusterLabelToHyperedge(children_labels, partitions[0], hyperedge_dict)\n",
    "        # entity\n",
    "        entity_titles = [entity['title'] for entity in hyperedges]\n",
    "        if hierarchy['key'] in topic_dict: return # if already have a topic, skip. This happens when continuing from a break point\n",
    "\n",
    "        # generate the topic\n",
    "        gpt_topic = query_leaf_topic(entity_titles, node_type='entity')\n",
    "        # record the result\n",
    "        topic_dict[hierarchy['key']] = gpt_topic\n",
    "        save_json(topic_dict, filepath)\n",
    "        print(hierarchy['key'], gpt_topic)\n",
    "        return\n",
    "    else:\n",
    "        sub_topic_samples = [] # samples from the sub-topics\n",
    "        all_hyperedges = []\n",
    "        # standard dfs\n",
    "        for child in hierarchy['children']:\n",
    "            dfs(child, partitions, hyperedge_dict, topic_dict, filepath, sampleFlag)\n",
    "            # sample from the sub-topics\n",
    "            level = int(child['key'].split('-')[1])\n",
    "            hyperedges = clusterLabelToHyperedge([child['key']], partitions[level], hyperedge_dict)\n",
    "            if sampleFlag:\n",
    "                sample = hyperedges[0]\n",
    "                sub_topic_samples.append(sample)\n",
    "            all_hyperedges += hyperedges\n",
    "        if hierarchy['key'] in topic_dict: return # if already have a topic, skip. This happens when continuing from a break point\n",
    "        # use the sub-topics and samples to generate a topic for the current node\n",
    "        # article\n",
    "        # cluster_subtopics = [topic_dict[child['key']] for child in hierarchy['children']]\n",
    "\n",
    "        # entity\n",
    "        cluster_subtopics = [topic_dict[child['key']].split(\",\") for child in hierarchy['children']]\n",
    "        cluster_subtopics = [item.strip() for sublist in cluster_subtopics for item in sublist] # flatten\n",
    "        if sampleFlag:\n",
    "            sample_hyperedges = random.sample(all_hyperedges, min(20, len(all_hyperedges)))\n",
    "        # generate the topic\n",
    "        # article\n",
    "        # gpt_topic = query_cluster_topic(cluster_subtopics, sample_hyperedges)\n",
    "        # entity\n",
    "        print(\"non-leaf: \", cluster_subtopics)\n",
    "        gpt_topic = query_leaf_topic(cluster_subtopics, node_type='entity')\n",
    "        # record the result\n",
    "        topic_dict[hierarchy['key']] = gpt_topic\n",
    "        save_json(topic_dict, filepath)\n",
    "        print(hierarchy['key'], gpt_topic)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is where the main function begins\n",
    "### I've helped you change the variable names (from hyperedges to entities) and kept the original line. \n",
    "### You should know that when I wrote the code, hyperedges == articles.\n",
    "### In your context, you will operate on entities instead.\n",
    "### This is just for your reference when you want to understand the testing/debugging codes\n",
    "### Be aware that in the dfs functions, variables of 'hyperedges' is not renamed to 'entities'. \n",
    "### Rename them if you feel confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read in hierarchy and partition\n",
    "# entity\n",
    "hierarchy = json.load(open('data/result/AllTheNews/network/server/ravasz_hierarchies_entity.json'))\n",
    "partitions = json.load(open('data/result/AllTheNews/network/server/ravasz_partitions_entity.json'))\n",
    "# article\n",
    "# hierarchy = json.load(open('data/result/AllTheNews/network/server/ravasz_hierarchies_article.json'))\n",
    "# partitions = json.load(open('data/result/AllTheNews/network/server/ravasz_partitions_article.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Read in entities. \n",
    "entities_dict = json.load(open('data/result/AllTheNews/network/entities.json'))\n",
    "# hyperedges_dict = json.load(open('data/result/AllTheNews/network/hyperedges.json')) # the original line\n",
    "\n",
    "# 3. generate topic. hierarchical_topics.json should be empty at first\n",
    "# entity\n",
    "topic_dict = json.load(open('data/result/AllTheNews/hierarchical_topics_entities_raw.json'))\n",
    "breakpoint_filepath = 'data/result/AllTheNews/hierarchical_topics_entities_raw.json'\n",
    "\n",
    "# article\n",
    "# topic_dict = json.load(open('data/result/AllTheNews/hierarchical_topics_articles.json'))\n",
    "# topic_dict = add_hierarchical_topic(hierarchy, partitions, hyperedges_dict, topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-leaf:  ['Education Institutions', 'Religious Institutions', 'Individuals in academia', 'Fraternities and Sororities', 'ten teachers', 'teachers union bosses', 'Education Trust', 'Education', 'Schools', 'Students', 'Sexual assault cases', 'Galaxies', 'his children', 'child soldiers', 'Children in America', 'residents in food deserts']\n",
      "L-3-57 Education Institutions, Religious Institutions, Individuals in academia, Fraternities and Sororities, Students, Sexual assault cases, Galaxies, Child soldiers, Children in America, Residents in food deserts\n"
     ]
    }
   ],
   "source": [
    "topic_dict = add_hierarchical_topic(hierarchy, partitions, entities_dict, topic_dict, breakpoint_filepath, sampleFlag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are testing/debugging functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = defaultdict(list)\n",
    "for node_id, cluster_id in partitions[1].items():\n",
    "    clusters[cluster_id].append(node_id)\n",
    "hyperedges_2344 = [hyperedges_dict[hyperedge_id] for hyperedge_id in clusters[2344]]\n",
    "query_leaf_topic(hyperedges_2344)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_cluster = hierarchy['children'][0]['children'][0]['children'][1]['children'][1]\n",
    "target_cluster = hierarchy['children'][2]['children'][1]['children'][1]['children'][0]\n",
    "len(target_cluster), [cluster['key'] for cluster in target_cluster], target_cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cluster = hierarchy['children'][2]['children'][1]['children'][1]['children'][0]\n",
    "topics = json.load(open('data/result/AllTheNews/hierarchical_topics_entities_mod.json'))\n",
    "cluster_children = [child['key'] for child in target_cluster['children']]\n",
    "sub_topic_samples = []\n",
    "# topic_dict = {}\n",
    "# for child in target_cluster['children']:\n",
    "    # # if len(child['children']) > 10 or len(child['children']) < 3: \n",
    "    # #     continue\n",
    "    # level = int(child['key'].split('-')[1])\n",
    "    # entities = clusterLabelToHyperedge([child['key']], partitions[level], entities_dict)\n",
    "    # entity_titles = [entity['title'] for entity in entities]\n",
    "    # print(target_cluster['key'], topics[target_cluster['key']], child['key'], len(entities), len(child['children']))\n",
    "    # print(\", \".join(entity_titles))\n",
    "    # sub_topic = topics[child['key']]\n",
    "    # print(sub_topic, new_sub_topic)\n",
    "    # print(\"----------------------\")\n",
    "    # topic_dict[child['key']] = sub_topic\n",
    "    # sample = hyperedges[0]\n",
    "    # sub_topic_samples.append(sample)\n",
    "cluster_subtopics = [topic_dict[child['key']].split(\",\") for child in target_cluster['children']]\n",
    "cluster_subtopics = [item.strip() for sublist in cluster_subtopics for item in sublist] # flatten\n",
    "new_sub_topic = query_leaf_topic(cluster_subtopics, 'entity')\n",
    "print(target_cluster['key'], topic_dict[target_cluster['key']])\n",
    "print(cluster_subtopics)\n",
    "print(new_sub_topic)\n",
    "print(\"---------------------\")\n",
    "# pprint(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = [752, 1069, 1070, 1478]\n",
    "# cluster_subtopics = [\n",
    "#     'Increasing Gun Violence in Chicago',\n",
    "#     'Crime Rates and Policing Tactics',\n",
    "#     'Misconceptions about Crime in the United States',\n",
    "#     'Global Events and Optimism',\n",
    "# ]\n",
    "cluster_subtopics = [topic_dict[\"L-1-{}\".format(cluster_label)] for cluster_label in children]\n",
    "cluster_samples = []\n",
    "clusters = defaultdict(list)\n",
    "for node_id, cluster_label in partitions[1].items():\n",
    "    clusters[cluster_label].append(node_id)\n",
    "for cluster_label in children:\n",
    "    cluster_samples += clusters[cluster_label]\n",
    "cluster_samples = random.sample(cluster_samples, 10)\n",
    "cluster_samples = [hyperedges_dict[sample] for sample in cluster_samples]\n",
    "topic = query_cluster_topic(cluster_subtopics, cluster_samples)\n",
    "sample_summaries = [sample['summary'] for sample in cluster_samples]\n",
    "print(topic)\n",
    "pprint(cluster_subtopics)\n",
    "for summary in sample_summaries:\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for generating few-show examples for the prompt\n",
    "sample_summaries = \"Sub-topics: \"\n",
    "sample_summaries += \", \".join(cluster_subtopics) + '\\n\\n\\n'\n",
    "for index, cluster_sample in enumerate(cluster_samples):\n",
    "    sample_summaries += \"Article {}: \\n\".format(index+1)\n",
    "    sample_summaries += cluster_sample['summary'] + '\\n\\n\\n'\n",
    "example = json.load(open(r'data/result/AllTheNews/cluster_summary/example.json'))\n",
    "example['non-leaf']['summaries'] = sample_summaries\n",
    "example['non-leaf']['topic'] = 'Crimes in the United States'\n",
    "save_json(example, r'data/result/AllTheNews/cluster_summary/example.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = json.load(open('data/result/AllTheNews/hierarchical_topics_entities_raw.json'))\n",
    "level_1_topics = {}\n",
    "for cluster, topic in topics.items():\n",
    "    level = int(cluster.split(\"-\")[1])\n",
    "    if level < 2:\n",
    "        level_1_topics[cluster] = topic\n",
    "save_json(level_1_topics, 'data/result/AllTheNews/hierarchical_topics_entities_raw.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "event_hgraph_preprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
